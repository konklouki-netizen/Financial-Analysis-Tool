# app.py (v2.3 - Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÎœÎ­ÏƒÎ¿Ï… ÎŒÏÎ¿Ï… ÎšÎ»Î¬Î´Î¿Ï… (Industry Average))
import streamlit as st
import pandas as pd
import os
import sys
import unicodedata 
import datetime 
import plotly.graph_objects as go 
from typing import Tuple, List, Dict, Any, Optional

# === v2.0: ÎÎ•Î‘ Î•Î™Î£Î‘Î“Î©Î“Î— ===
from finvizfinance.quote import finvizfinance
# === === === === === === ===

# === v1.25 FIX: Î— "Î‘Î»ÎµÎ¾Î¯ÏƒÏ†Î±Î¹ÏÎ·" Î”Î¹ÏŒÏÎ¸Ï‰ÏƒÎ· Path ===
script_dir = os.path.dirname(os.path.abspath(__file__))
if script_dir not in sys.path:
    sys.path.append(script_dir)
# === === === === === === === === === ===

# === Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® PDF Exporter ===
try:
    from modules.pdf_exporter import create_pdf_report
except ImportError:
    st.error("ÎšÎ¡Î™Î£Î™ÎœÎŸ Î£Î¦Î‘Î›ÎœÎ‘: Î”Î•Î Î’Î¡Î•Î˜Î—ÎšÎ• Ï„Î¿ 'modules/pdf_exporter.py'. Î’ÎµÎ²Î±Î¹ÏÏƒÎ¿Ï… ÏŒÏ„Î¹ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ 'modules'.")
    st.stop()
# === === === === === === === === ===

# === Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Ï„Ï‰Î½ "Î•Î³ÎºÎµÏ†Î¬Î»Ï‰Î½" Î¼Î±Ï‚ (v2.3) ===
try:
    # Î¤Î©Î¡Î‘ Î•Î™Î£Î‘Î“ÎŸÎ¥ÎœÎ• ÎšÎ‘Î™ Î¤Î— ÎÎ•Î‘ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î—
    from test_loader import resolve_to_ticker, load_company_info, get_company_df, normalize_dataframe, get_industry_tickers 
    from modules.analyzer import calculate_financial_ratios
except ImportError as e:
    st.error(f"ÎšÎ¡Î™Î£Î™ÎœÎŸ Î£Î¦Î‘Î›ÎœÎ‘: {e}")
    st.error("Î’ÎµÎ²Î±Î¹ÏÏƒÎ¿Ï… ÏŒÏ„Î¹ Ï„Î± 'app.py', 'test_loader.py', ÎºÎ±Î¹ Î¿ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ 'modules' ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿Î½ Î¯Î´Î¹Î¿ ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿.")
    st.stop() 
# === === === === === === === === ===

# === Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î£ÎµÎ»Î¯Î´Î±Ï‚ ===
st.set_page_config(
    page_title="Financial Analysis Tool v2.3", # <--- ÎÎ­Î± Î­ÎºÎ´Î¿ÏƒÎ·
    page_icon="ğŸ“Š",
    layout="wide" 
)

# === v2.0: Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· "ÎœÎ½Î®Î¼Î·Ï‚" (Session State) ===
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'analysis_inputs' not in st.session_state:
    st.session_state.analysis_inputs = {}
if 'company_info_loaded' not in st.session_state:
    st.session_state.company_info_loaded = False
if 'company_info_data' not in st.session_state:
    st.session_state.company_info_data = {}
# === === === === === === === === === ===

# === v1.15: "Î¥Ï€Î­Ï-ÎˆÎ¾Ï…Ï€Î½Î¿Ï‚ Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î®Ï‚" PDF ===
def _find_and_merge_pdf_tables(raw_data_list: list) -> Tuple[pd.DataFrame, dict]:
    """
    Î‘Ï…Ï„ÏŒÏ‚ ÎµÎ¯Î½Î±Î¹ Î¿ "Î¥Ï€Î­Ï-ÎˆÎ¾Ï…Ï€Î½Î¿Ï‚ Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î®Ï‚" (v1.15).
    ÎšÎ±Î»ÎµÎ¯Ï„Î±Î¹ **ÎœÎŸÎÎŸ** Î³Î¹Î± Ï€Î·Î³Î­Ï‚ PDF.
    """
    st.info("ğŸ” Î•ÎºÏ„Î­Î»ÎµÏƒÎ· 'Î¥Ï€Î­Ï-ÎˆÎ¾Ï…Ï€Î½Î¿Ï… Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î®' PDF (v1.15)...")
    
    INCOME_KEYS = ['income statement', 'ÎºÎ±Ï„Î±ÏƒÏ„Î±ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Ï‰Î½', 'results of operations', 'revenue', 'net income', 'Î­ÏƒÎ¿Î´Î±', 'ÎºÎ­ÏÎ´Î·']
    BALANCE_KEYS = ['balance sheet', 'Î¹ÏƒÎ¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ïƒ', 'financial position', 'total assets', 'total liabilities', 'ÎµÎ½ÎµÏÎ³Î·Ï„Î¹ÎºÏŒ', 'Ï…Ï€Î¿Ï‡ÏÎµÏÏƒÎµÎ¹Ï‚']
    CASH_KEYS = ['cash flow', 'Ï„Î±Î¼ÎµÎ¹Î±ÎºÎµÏƒ ÏÎ¿ÎµÏƒ', 'operating activities', 'investing activities', 'financing activities', 'operating cash flow']

    found_tables = {
        "income": pd.DataFrame(),
        "balance": pd.DataFrame(),
        "cashflow": pd.DataFrame()
    }
    
    debug_log = {} 

    # 1. Î’ÏÎµÏ‚ Ï„Î¿Ï…Ï‚ 3 Ï€Î¯Î½Î±ÎºÎµÏ‚
    for item in raw_data_list:
        title = item.get("title", "").lower()
        table_df = item.get("table")
        
        if table_df is None or table_df.empty:
            continue
            
        try:
            if table_df.shape[1] > 0:
                first_col_content = " ".join(table_df.iloc[:, 0].astype(str)).lower()
            else:
                first_col_content = ""
        except Exception:
            first_col_content = "" 

        search_corpus = title + " " + first_col_content

        if any(key in search_corpus for key in INCOME_KEYS) and found_tables["income"].empty:
            st.write(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'Income' (Î¤Î¯Ï„Î»Î¿Ï‚: {title})")
            found_tables["income"] = table_df
            debug_log["Income Statement (Raw)"] = table_df
            
        elif any(key in search_corpus for key in BALANCE_KEYS) and found_tables["balance"].empty:
            st.write(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'Balance' (Î¤Î¯Ï„Î»Î¿Ï‚: {title})")
            found_tables["balance"] = table_df
            debug_log["Balance Sheet (Raw)"] = table_df

        elif any(key in search_corpus for key in CASH_KEYS) and found_tables["cashflow"].empty:
            st.write(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'CashFlow' (Î¤Î¯Ï„Î»Î¿Ï‚: {title})")
            found_tables["cashflow"] = table_df
            debug_log["Cash Flow (Raw)"] = table_df

    # 2. "ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎµ" (Pivot/Normalize) Ï„Î¿Ï…Ï‚ 3 Ï€Î¯Î½Î±ÎºÎµÏ‚
    final_dfs = []

    if not found_tables["income"].empty:
        st.write("...ÎœÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÏ„Î±Î¹ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'Income'...")
        df = normalize_dataframe(found_tables["income"], source_type="pdf") 
        if not df.empty:
            final_dfs.append(df)
            debug_log["Income Statement (Normalized)"] = df
        else:
             st.warning("   > Î— 'ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·' Ï„Î¿Ï… Income Î±Ï€Î­Ï„Ï…Ï‡Îµ (Ï€.Ï‡. Î´ÎµÎ½ Î²ÏÎ®ÎºÎµ Ï‡ÏÎ¿Î½Î¹Î­Ï‚).")

            
    if not found_tables["balance"].empty:
        st.write("...ÎœÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÏ„Î±Î¹ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'Balance'...")
        df = normalize_dataframe(found_tables["balance"], source_type="pdf")
        if not df.empty:
            final_dfs.append(df)
            debug_log["Balance Sheet (Normalized)"] = df
        else:
             st.warning("   > Î— 'ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·' Ï„Î¿Ï… Balance Î±Ï€Î­Ï„Ï…Ï‡Îµ (Ï€.Ï‡. Î´ÎµÎ½ Î²ÏÎ®ÎºÎµ Ï‡ÏÎ¿Î½Î¹Î­Ï‚).")

    if not found_tables["cashflow"].empty:
        st.write("...ÎœÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÏ„Î±Î¹ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'CashFlow'...")
        df = normalize_dataframe(found_tables["cashflow"], source_type="pdf")
        if not df.empty:
            final_dfs.append(df)
            debug_log["Cash Flow (Normalized)"] = df
        else:
             st.warning("   > Î— 'ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·' Ï„Î¿Ï… CashFlow Î±Ï€Î­Ï„Ï…Ï‡Îµ (Ï€.Ï‡. Î´ÎµÎ½ Î²ÏÎ®ÎºÎµ Ï‡ÏÎ¿Î½Î¹Î­Ï‚).")

    # 3. Î¤ÎµÎ»Î¹ÎºÎ® ÎˆÎ½Ï‰ÏƒÎ· (Merge)
    if not final_dfs:
        st.error("âŒ ÎŸ 'Î¥Ï€Î­Ï-ÎˆÎ¾Ï…Ï€Î½Î¿Ï‚ Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î®Ï‚' Î±Ï€Î­Ï„Ï…Ï‡Îµ. Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î® Î´ÎµÎ½ Î¼ÎµÏ„Î±Ï†ÏÎ¬ÏƒÏ„Î·ÎºÎµ ÎºÎ±Î½Î­Î½Î±Ï‚ Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚.")
        return pd.DataFrame(), debug_log

    st.write("...Î¤ÎµÎ»Î¹ÎºÎ® Î­Î½Ï‰ÏƒÎ· (merge) Ï„Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½...")
    
    final_golden_df = pd.DataFrame()
    try:
        final_golden_df = final_dfs[0]
        if len(final_dfs) > 1:
            for i in range(1, len(final_dfs)):
                if 'Year' in final_golden_df.columns and 'Year' in final_dfs[i].columns:
                    final_golden_df = pd.merge(final_golden_df, final_dfs[i], on="Year", how="outer")
                else:
                     st.warning(f"   > Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± 'Merge': ÎˆÎ½Î±Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î±Î³Î½Î¿Î®Î¸Î·ÎºÎµ (Î­Î»ÎµÎ¹Ï€Îµ Ï„Î¿ 'Year').")
                    
    except Exception as e:
        st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± 'Merge': {e}")
        return pd.DataFrame(), debug_log

    final_golden_df = final_golden_df.loc[:, ~final_golden_df.columns.duplicated()]
    
    if 'Year' in final_golden_df.columns:
        final_golden_df['Year'] = pd.to_numeric(final_golden_df['Year'], errors='coerce').fillna(0).astype(int)

    return final_golden_df, debug_log
# === === === === === === === === === ===


# === 1. Î— Î Î»Î±ÏŠÎ½Î® ÎœÏ€Î¬ÏÎ± (Sidebar) - Î¤Î± Î•ÏÎ³Î±Î»ÎµÎ¯Î± Î•Î¹ÏƒÏŒÎ´Î¿Ï… ===
st.sidebar.title("ğŸ“Š Î•ÏÎ³Î±Î»ÎµÎ¯Î± Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ (v2.3)") # <--- ÎÎ­Î± Î­ÎºÎ´Î¿ÏƒÎ·
st.sidebar.markdown("Î”Î¹Î¬Î»ÎµÎ¾Îµ Ï„Î·Î½ Ï€Î·Î³Î® ÎºÎ±Î¹ Ï„Î·Î½ ÎµÏ„Î±Î¹ÏÎµÎ¯Î± ÏƒÎ¿Ï….")

def reset_analysis_state():
    """v2.0: ÎšÎ¬Î½ÎµÎ¹ reset Ï„Î± Ï€Î¬Î½Ï„Î± ÏŒÏ„Î±Î½ Î±Î»Î»Î¬Î¶ÎµÎ¹ Î· Ï€Î·Î³Î®."""
    st.session_state.analysis_results = None
    st.session_state.analysis_inputs = {}
    st.session_state.company_info_loaded = False
    st.session_state.company_info_data = {}

source_options = ["Yahoo", "CSV", "Excel", "PDF"] 
source_type = st.sidebar.selectbox(
    "Î•Ï€Î¯Î»ÎµÎ¾Îµ Î Î·Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:",
    source_options,
    key="source_type_select",
    on_change=reset_analysis_state
)

# Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÏÎ½
raw_input: Optional[str] = None 
uploaded_file: Optional[Any] = None
selected_peers: List[str] = []

# --- Î›Î¿Î³Î¹ÎºÎ® Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î·Î½ Î Î·Î³Î® ---
if source_type in ["CSV", "Excel", "PDF"]: 
    st.sidebar.warning("Î— Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎµÏÏÎµÏƒÎ· Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„ÏÎ½ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î¼ÏŒÎ½Î¿ Î¼Îµ Ï„Î·Î½ Ï€Î·Î³Î® 'Yahoo'.")
    
    file_types: List[str] = []
    if source_type == "CSV": file_types = ["csv"]
    elif source_type == "Excel": file_types = ["xlsx", "xls"]
    elif source_type == "PDF": file_types = ["pdf"]

    uploaded_file = st.sidebar.file_uploader(
        f"Î‘Î½Î­Î²Î±ÏƒÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ÏƒÎ¿Ï… ({source_type})", 
        type=file_types,
        key="file_uploader",
        on_change=reset_analysis_state
    )
    if uploaded_file:
        st.session_state.company_info_loaded = True
        st.session_state.company_info_data = {
            "ticker": "File",
            "source_name": uploaded_file.name,
            "industry": "General",
            "country": "N/A (from file)",
            "info_df": pd.DataFrame([{"ÎŒÎ½Î¿Î¼Î±": uploaded_file.name, "ÎšÎ»Î¬Î´Î¿Ï‚": "General", "Î§ÏÏÎ±": "N/A (from file)", "Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·": "Î‘Î½Î¬Î»Ï…ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿Ï€Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿"}]),
            "peer_list": [] 
        }


elif source_type == "Yahoo":
    raw_input = st.sidebar.text_input(
        "Ticker Î® ÎŒÎ½Î¿Î¼Î± ÎšÏÏÎ¹Î±Ï‚ Î•Ï„Î±Î¹ÏÎµÎ¯Î±Ï‚:", 
        "MSFT", 
        key="ticker_input",
        on_change=reset_analysis_state
    )
    
    if st.sidebar.button("Î•ÏÏÎµÏƒÎ· Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ & Î‘Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„ÏÎ½", key="find_peers"):
        if raw_input:
            with st.spinner(f"Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± '{raw_input}'..."):
                ticker = resolve_to_ticker(raw_input, source_type="yahoo")
            if ticker:
                st.success(f"Î’ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Ticker: **{ticker}**")
                with st.spinner(f"Î›Î®ÏˆÎ· Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ & Î‘Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„ÏÎ½ Î³Î¹Î± {ticker}..."):
                    try:
                        info_df, industry = load_company_info(ticker)
                        country = info_df['Î§ÏÏÎ±'].iloc[0]
                        
                        stock_finviz = finvizfinance(ticker)
                        peer_list = stock_finviz.ticker_peer()
                        
                        st.session_state.company_info_loaded = True
                        st.session_state.company_info_data = {
                            "ticker": ticker,
                            "source_name": info_df['ÎŒÎ½Î¿Î¼Î±'].iloc[0] or ticker,
                            "info_df": info_df,
                            "industry": industry,
                            "country": country,
                            "peer_list": peer_list
                        }
                        
                    except Exception as e:
                        st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î»Î®ÏˆÎ·Ï‚ Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„ÏÎ½ (ÎŠÏƒÏ‰Ï‚ Ï„Î¿ Finviz Î±Ï€Î­ÎºÎ»ÎµÎ¹ÏƒÎµ Ï„Î·Î½ IP): {e}")
                        info_df, industry = load_company_info(ticker)
                        country = info_df['Î§ÏÏÎ±'].iloc[0]
                        st.session_state.company_info_loaded = True
                        st.session_state.company_info_data = {
                            "ticker": ticker,
                            "source_name": info_df['ÎŒÎ½Î¿Î¼Î±'].iloc[0] or ticker,
                            "info_df": info_df,
                            "industry": industry,
                            "country": country,
                            "peer_list": [] # Î†Î´ÎµÎ¹Î± Î»Î¯ÏƒÏ„Î±
                        }
            else:
                st.error(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î­Î³ÎºÏ…ÏÎ¿ Ticker Î³Î¹Î± Ï„Î¿ '{raw_input}'.")
        else:
            st.warning("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Î­Î½Î± Ticker Î® ÎŒÎ½Î¿Î¼Î±.")


# === v2.0: ÎÎ•Î‘ Î›ÎŸÎ“Î™ÎšÎ— (Î•Î¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ *Î¼ÎµÏ„Î¬* Ï„Î·Î½ ÎµÏÏÎµÏƒÎ·) ===
if st.session_state.company_info_loaded:
    
    peers_info = st.session_state.company_info_data
    
    st.sidebar.success(f"Î•Ï„Î±Î¹ÏÎµÎ¯Î±: {peers_info['ticker']} ({peers_info['industry']})")
    st.sidebar.caption(f"Î§ÏÏÎ±: {peers_info.get('country', 'N/A')}")
    
    if peers_info.get("peer_list"):
        st.sidebar.subheader("Î•Ï€Î¹Î»Î¿Î³Î® Î‘Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„ÏÎ½")
        selected_peers = st.sidebar.multiselect(
            "Î•Ï€Î¯Î»ÎµÎ¾Îµ 0 Î® Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿Ï…Ï‚ Î³Î¹Î± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·:",
            options=peers_info["peer_list"],
            key="peers_multiselect"
        )
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("Î•Ï€Î¹Î»Î¿Î³Î® Î§ÏÎ¿Î½Î¹ÎºÎ¿Ï Î”Î¹Î±ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚")
    current_year = datetime.datetime.now().year
    
    start_year = st.sidebar.number_input("Î‘Ï€ÏŒ (ÎˆÏ„Î¿Ï‚):", 2018, current_year - 1, value=current_year-5, key="start_year")
    end_year = st.sidebar.number_input("ÎˆÏ‰Ï‚ (ÎˆÏ„Î¿Ï‚):", 2019, current_year + 5, value=current_year, key="end_year")

    if start_year > end_year:
        st.sidebar.error("Î¤Î¿ 'Î‘Ï€ÏŒ' Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¼ÎµÏ„Î¬ Ï„Î¿ 'ÎˆÏ‰Ï‚'.")
        st.stop()

    if st.sidebar.button("ğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚", key="analyze_main"):
        st.session_state.analysis_results = None 
        st.session_state.analysis_inputs = {
            "source_type": source_type,
            "source_name": peers_info["source_name"],
            "main_ticker": peers_info["ticker"],
            "info_df_main": peers_info["info_df"],
            "industry_main": peers_info["industry"],
            "selected_peers": selected_peers, 
            "uploaded_file_bytes": uploaded_file.getvalue() if uploaded_file else None,
            "uploaded_file_name": uploaded_file.name if uploaded_file else None,
            "start_year": start_year,
            "end_year": end_year
        }
        analyze_button_pressed = True 
    else:
        analyze_button_pressed = False

else:
    analyze_button_pressed = False
# === === === === === === === === === ===


# === 2. ÎšÎµÎ½Ï„ÏÎ¹ÎºÎ® Î£ÎµÎ»Î¯Î´Î± - Î¤Î± Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ===
st.title("ğŸ“Š Financial Analysis Dashboard (v2.3)") # <--- ÎÎ­Î± Î­ÎºÎ´Î¿ÏƒÎ·

if st.session_state.analysis_inputs:
    
    inputs = st.session_state.analysis_inputs
    source_type = inputs["source_type"]
    source_name = inputs["source_name"]
    start_year = inputs["start_year"]
    end_year = inputs["end_year"]
    main_ticker = inputs["main_ticker"] 

    st.markdown(f"Î‘Î½Î¬Î»Ï…ÏƒÎ· Î³Î¹Î±: **{source_name}** (Î Î·Î³Î®: {source_type})")

    if st.session_state.analysis_results and not analyze_button_pressed:
        st.info("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ Î±Ï€ÏŒ Ï„Î· Î¼Î½Î®Î¼Î·...")
        results = st.session_state.analysis_results
    
    else:
        # --- Î‘Î Î”Î•Î Î•Î™ÎÎ‘Î™ Î£Î¤Î— ÎœÎÎ—ÎœÎ—: ÎšÎ‘ÎÎ• Î¤Î—Î Î‘ÎÎ‘Î›Î¥Î£Î— (Î‘Î¡Î“ÎŸ) ---
        
        all_info_dfs = {}
        all_company_dfs_normalized = {}
        all_debug_tables = {}
        
        # NEW: Î¨ÎµÏ…Î´ÏÎ½Ï…Î¼Î¿ Î³Î¹Î± Ï„Î¿Î½ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿
        INDUSTRY_AVG_TICKER = "INDUSTRY_AVG" 
        industry_ratios_to_save = {}
        sector_main = "General" # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        
        # === [ÎÎ•ÎŸ Î’Î—ÎœÎ‘ Î“.1] Î›Î®ÏˆÎ· & Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… ÎŒÏÎ¿Ï… ÎšÎ»Î¬Î´Î¿Ï… ===
        if source_type == "Yahoo":
            sector_main = inputs["info_df_main"]['ÎšÎ»Î¬Î´Î¿Ï‚'].iloc[0] 
            
            with st.spinner(f"Î›Î®ÏˆÎ· Tickers Î³Î¹Î± Ï„Î¿Î½ ÎºÎ»Î¬Î´Î¿ '{sector_main}'..."):
                # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î· Î½Î­Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ ÎŸÎ›ÎŸÎ¥Î£ Ï„Î¿Ï…Ï‚ Ï€Î¹Î¸Î±Î½Î¿ÏÏ‚ tickers (Î­Ï‰Ï‚ 50)
                all_industry_tickers = get_industry_tickers(industry_name=sector_main, sector_name=sector_main)
            
            if all_industry_tickers:
                st.info(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(all_industry_tickers)} ÎµÏ„Î±Î¹ÏÎµÎ¯ÎµÏ‚ ÏƒÏ„Î¿Î½ ÎºÎ»Î¬Î´Î¿. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… ÎŒÏÎ¿Ï…...")
                
                all_industry_ratios = [] 
                
                # --- ÎšÏÎºÎ»Î¿Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ ÎšÎ»Î¬Î´Î¿Ï… ---
                for ind_ticker in all_industry_tickers:
                    try:
                        # Î›Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                        raw_data_list_ind = get_company_df(ind_ticker, source_type="yahoo", period="max")
                        if not raw_data_list_ind: continue
                        raw_table_ind = raw_data_list_ind[0]["table"]
                        company_df_ind = normalize_dataframe(raw_table_ind, source_type="yahoo")
                        
                        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± ÎµÏ„ÏÎ½ 
                        if 'Year' in company_df_ind.columns:
                            company_df_ind['Year'] = pd.to_numeric(company_df_ind['Year'], errors='coerce').fillna(0).astype(int)
                            company_df_ind = company_df_ind[
                                (company_df_ind['Year'] >= start_year) & 
                                (company_df_ind['Year'] <= end_year)
                            ].copy()
                        
                        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î”ÎµÎ¹ÎºÏ„ÏÎ½
                        if not company_df_ind.empty:
                            # Î•Î´Ï ÎºÎ±Î»Î¿ÏÎ¼Îµ Ï„Î·Î½ calculate_financial_ratios Î±Ï€ÏŒ Ï„Î¿ analyzer
                            ind_result = calculate_financial_ratios(company_df_ind, sector=sector_main)
                            if ind_result.get("categories"):
                                all_industry_ratios.append(ind_result["categories"])
                        
                    except Exception:
                        # Î Î±ÏÎ±Î»ÎµÎ¯Ï€Î¿Ï…Î¼Îµ Ï„Î± ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± Î±Ï€ÏŒ Î¼ÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½ÎµÏ‚ ÎµÏ„Î±Î¹ÏÎµÎ¯ÎµÏ‚
                        continue 
                
                # --- Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÏ‰Î½ ÎŒÏÏ‰Î½ ---
                if all_industry_ratios:
                    st.info(f"Î•Ï€Î¹Ï„Ï…Ï‡Î®Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ· {len(all_industry_ratios)} ÎµÏ„Î±Î¹ÏÎµÎ¹ÏÎ½ Ï„Î¿Ï… ÎºÎ»Î¬Î´Î¿Ï… Î³Î¹Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ Î¼Î­ÏƒÎ¿Ï… ÏŒÏÎ¿Ï….")
                    
                    # Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ (mean) Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒ ÎˆÏ„Î¿Ï…Ï‚/Î”ÎµÎ¯ÎºÏ„Î·
                    sample_categories = all_industry_ratios[0].keys()
                    
                    for category in sample_categories:
                        all_dfs_for_category = []
                        for ratios_dict in all_industry_ratios:
                            if category in ratios_dict:
                                # Flatten DataFrame (Year, Ratio, Value)
                                df = ratios_dict[category].set_index('Year').stack().reset_index()
                                df.columns = ['Year', 'Ratio', 'Value']
                                all_dfs_for_category.append(df)
                        
                        if all_dfs_for_category:
                            merged_category_df = pd.concat(all_dfs_for_category)
                            
                            # Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ (mean) Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒ ÎˆÏ„Î¿Ï…Ï‚/Î”ÎµÎ¯ÎºÏ„Î·
                            avg_df = merged_category_df.groupby(['Year', 'Ratio'])['Value'].mean().reset_index()
                            
                            # ÎÎ±Î½Î±Î³Ï…ÏÎ¯Î¶Î¿Ï…Î¼Îµ ÏƒÏ„Î¿Î½ Î±ÏÏ‡Î¹ÎºÏŒ Ï€Î¯Î½Î±ÎºÎ± (Year, Ratio1, Ratio2, ...)
                            avg_df_pivot = avg_df.pivot(index='Year', columns='Ratio', values='Value').reset_index()
                            
                            industry_ratios_to_save[category] = avg_df_pivot
                    
                    st.success(f"âœ… Î¥Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎµ Î¿ ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ ÎšÎ»Î¬Î´Î¿Ï….")
        
        # === Î’Î—ÎœÎ‘ Î‘: Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ¥Î¡Î™Î‘Î£ Î•Î¤Î‘Î™Î¡Î•Î™Î‘Î£ ===
        all_info_dfs[main_ticker] = inputs["info_df_main"]
        industry_main = inputs["industry_main"]
        
        if source_type == "Yahoo":
            with st.spinner(f"Î›Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± {main_ticker}..."):
                raw_data_list = get_company_df(main_ticker, source_type=source_type.lower(), period="max")
                if not raw_data_list:
                    st.error(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ Yahoo Finance Î³Î¹Î± Ï„Î¿Î½ {main_ticker}.")
                    st.session_state.analysis_inputs = {}
                    st.stop()
                
                st.info(f"...ÎœÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÏ„Î±Î¹ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ 'Yahoo' ({main_ticker})...")
                raw_table_main = raw_data_list[0]["table"]
                company_df_main = normalize_dataframe(raw_table_main, source_type="yahoo")
                
                all_company_dfs_normalized[main_ticker] = company_df_main
                all_debug_tables[main_ticker] = {"Yahoo Finance Data (Raw)": raw_table_main, "Yahoo Finance Data (Normalized)": company_df_main}

        elif source_type in ["CSV", "Excel", "PDF"] and inputs["uploaded_file_bytes"] is not None:
            with st.spinner(f"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… '{source_name}'..."):
                
                temp_dir = "temp"
                if not os.path.exists(temp_dir): os.makedirs(temp_dir)
                
                try:
                    normalized_name = unicodedata.normalize('NFKD', inputs["uploaded_file_name"]).encode('ascii', 'ignore').decode('ascii')
                    if not normalized_name or normalized_name.isspace(): normalized_name = "uploaded_file.tmp"
                except Exception:
                    normalized_name = "uploaded_file.tmp"
                    
                temp_file_path = os.path.join(temp_dir, normalized_name)
                
                with open(temp_file_path, "wb") as f: f.write(inputs["uploaded_file_bytes"])
                
                file_ext = source_type.lower()
                raw_data_list = get_company_df(temp_file_path, source_type=file_ext)
                
                if not raw_data_list:
                    st.error(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ {file_ext} Î±ÏÏ‡ÎµÎ¯Î¿.")
                    st.session_state.analysis_inputs = {}
                    st.stop()
                
                debug_tables_main = {"Source Type": file_ext}
                
                if file_ext == "pdf":
                    company_df_main, debug_pdf_tables_update = _find_and_merge_pdf_tables(raw_data_list)
                    debug_tables_main.update(debug_pdf_tables_update)
                else:
                    st.info(f"...ÎœÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÏ„Î±Î¹ Î¿ Î Î¯Î½Î±ÎºÎ±Ï‚ '{file_ext}'...")
                    raw_table_for_debug = raw_data_list[0]["table"]
                    company_df_main = normalize_dataframe(raw_table_for_debug, source_type=file_ext)
                    debug_tables_main.update({"File Data (Raw)": raw_table_for_debug, f"File Data ({file_ext}) (Normalized)": company_df_main})

                all_company_dfs_normalized[main_ticker] = company_df_main
                all_debug_tables[main_ticker] = debug_tables_main

        # === Î’Î—ÎœÎ‘ Î’: Î¦ÎŸÎ¡Î¤Î©Î£Î— Î‘ÎÎ¤Î‘Î“Î©ÎÎ™Î£Î¤Î©Î (v2.0) ===
        selected_peers = inputs["selected_peers"]
        for peer_ticker in selected_peers:
            with st.spinner(f"Î›Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„Î®: {peer_ticker}..."):
                try:
                    info_df_peer, _ = load_company_info(peer_ticker)
                    all_info_dfs[peer_ticker] = info_df_peer
                    
                    raw_data_list_peer = get_company_df(peer_ticker, source_type="yahoo", period="max")
                    if not raw_data_list_peer:
                        st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿Î½ {peer_ticker}. Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ·.")
                        continue
                    
                    raw_table_peer = raw_data_list_peer[0]["table"]
                    company_df_peer = normalize_dataframe(raw_table_peer, source_type="yahoo")
                    
                    all_company_dfs_normalized[peer_ticker] = company_df_peer
                    all_debug_tables[peer_ticker] = {"Yahoo Finance Data (Raw)": raw_table_peer, "Yahoo Finance Data (Normalized)": company_df_peer}
                    
                except Exception as e:
                    st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î»Î®ÏˆÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± {peer_ticker}: {e}")
        
        # === Î’Î—ÎœÎ‘ Î“.2: Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ‘ & Î¥Î ÎŸÎ›ÎŸÎ“Î™Î£ÎœÎŸÎ£ ÎšÎ¥Î¡Î™Î‘Î£ Î•Î¤Î‘Î™Î¡Î•Î™Î‘Î£ & Î‘ÎÎ¤Î‘Î“Î©ÎÎ™Î£Î¤Î©Î ===
        
        # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î»Î¯ÏƒÏ„Î±Ï‚ Î´ÎµÎ¹ÎºÏ„ÏÎ½
        all_ratios_categories = {}
        
        # âš ï¸ Î Î¡ÎŸÎ£Î˜Î•Î¤ÎŸÎ¥ÎœÎ• Î Î¡Î©Î¤Î‘ Î¤ÎŸÎ ÎœÎ•Î£ÎŸ ÎŸÎ¡ÎŸ ÎšÎ›Î‘Î”ÎŸÎ¥
        if industry_ratios_to_save:
            all_ratios_categories[INDUSTRY_AVG_TICKER] = industry_ratios_to_save
            # Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï†Ï„Î¹Î¬Î¾Î¿Ï…Î¼Îµ Î­Î½Î± Info DataFrame Î³Î¹Î± Ï„Î¿Î½ ÎºÎ»Î¬Î´Î¿, ÏÏƒÏ„Îµ Î½Î± Ï„Î¿ Î±Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Î¿ display
            all_info_dfs[INDUSTRY_AVG_TICKER] = pd.DataFrame([{"ÎŒÎ½Î¿Î¼Î±": f"ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ ÎšÎ»Î¬Î´Î¿Ï… ({sector_main})", "ÎšÎ»Î¬Î´Î¿Ï‚": sector_main, "Î§ÏÏÎ±": "Industry", "Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·": "Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î¿Ï‚ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚"}])
        
        all_company_dfs_analyzed = {}
        all_tickers_to_process = [main_ticker] + selected_peers
        
        # --- ÎšÏÎºÎ»Î¿Ï‚ Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚ (Main & Peers) ---
        for ticker in all_tickers_to_process:
            if ticker not in all_company_dfs_normalized or all_company_dfs_normalized[ticker].empty:
                st.warning(f"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î³Î¹Î± {ticker}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
                continue

            company_df = all_company_dfs_normalized[ticker]
            
            if 'Year' in company_df.columns:
                try:
                    company_df['Year'] = pd.to_numeric(company_df['Year'], errors='coerce').fillna(0).astype(int)
                    original_rows = len(company_df)
                    company_df_filtered = company_df[
                        (company_df['Year'] >= start_year) & 
                        (company_df['Year'] <= end_year)
                    ].copy()
                    
                    st.info(f"Î¦Î¯Î»Ï„ÏÎ¿ Î•Ï„ÏÎ½ ({ticker}): {start_year} - {end_year}. (Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(company_df_filtered)} Î±Ï€ÏŒ {original_rows} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚).")

                    if company_df_filtered.empty:
                        st.error(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± {ticker} ÏƒÏ„Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Ï‡ÏÎ¿Î½Î¹ÎºÏŒ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î±.")
                        continue
                    
                    company_df_to_analyze = company_df_filtered
                        
                except Exception as e:
                    st.warning(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¯ÏƒÎ¼Î±Ï„Î¿Ï‚ ÎµÏ„ÏÎ½ ({ticker}): {e}")
                    company_df_to_analyze = company_df
            else:
                st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î®Î»Î· 'Year' Î³Î¹Î± Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± ({ticker}).")
                company_df_to_analyze = company_df
            
            # --- Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î”ÎµÎ¹ÎºÏ„ÏÎ½ ---
            with st.spinner(f"Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ¹ÎºÏ„ÏÎ½ Î³Î¹Î± {ticker}..."):
                current_industry = all_info_dfs[ticker]['ÎšÎ»Î¬Î´Î¿Ï‚'].iloc[0] if ticker in all_info_dfs else "General"
                result = calculate_financial_ratios(company_df_to_analyze, sector=current_industry)
                
                # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
                all_ratios_categories[ticker] = result.get("categories", {})
                all_company_dfs_analyzed[ticker] = company_df_to_analyze

        # === v1.22: Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥Î£Î— ÎŸÎ›Î©Î Î¤Î©Î Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î ===
        st.session_state.analysis_results = {
            "all_info_dfs": all_info_dfs,
            "all_company_dfs_analyzed": all_company_dfs_analyzed,
            "all_ratios_categories": all_ratios_categories,
            "main_ticker": main_ticker,
            "selected_peers": selected_peers,
            "all_debug_tables": all_debug_tables
        }
        
        results = st.session_state.analysis_results
    
    # === === === === === === === === === === ===
    # === 3. Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (Î¤Î¡Î•Î§Î•Î™ Î Î‘ÎÎ¤Î‘) ===
    # === === === === === === === === === === ===
    
    all_info_dfs = results["all_info_dfs"]
    all_company_dfs_analyzed = results["all_company_dfs_analyzed"]
    all_ratios_categories = results["all_ratios_categories"]
    main_ticker = results["main_ticker"]
    selected_peers = results["selected_peers"]
    all_debug_tables = results["all_debug_tables"]
    
    # v2.3: Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î»Î¯ÏƒÏ„Î±Ï‚ tickers Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
    all_tickers_to_display = [main_ticker] + selected_peers
    
    # v2.3: Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¿Ï… INDUSTRY_AVG ÏƒÏ„Î· Î»Î¯ÏƒÏ„Î± tickers Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
    INDUSTRY_AVG_TICKER = "INDUSTRY_AVG"
    industry_avg_available = INDUSTRY_AVG_TICKER in all_info_dfs
    
    if industry_avg_available:
        all_tickers_to_display.append(INDUSTRY_AVG_TICKER)
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î•Ï€Î¹ÏƒÎºÎ¿Ï€Î®ÏƒÎµÏ‰Î½ (v2.3)
    for ticker in all_tickers_to_display:
        if ticker in all_info_dfs:
            st.header(f"Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·: {all_info_dfs[ticker]['ÎŒÎ½Î¿Î¼Î±'].iloc[0]}")
            st.dataframe(all_info_dfs[ticker], width=1200) 

    # --- Î›Î®ÏˆÎ· PDF (ÎœÏŒÎ½Î¿ Î³Î¹Î± Ï„Î·Î½ ÎšÏÏÎ¹Î± Î•Ï„Î±Î¹ÏÎµÎ¯Î±) ---
    with st.spinner("Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ PDF..."):
        pdf_data_raw = create_pdf_report(
            all_info_dfs[main_ticker], 
            all_ratios_categories.get(main_ticker, {}), 
            all_company_dfs_analyzed.get(main_ticker, pd.DataFrame())
        )
        pdf_bytes_fixed = bytes(pdf_data_raw)
        
        st.download_button(
            label="ğŸ“¥ Î›Î®ÏˆÎ· Î‘Î½Î±Ï†Î¿ÏÎ¬Ï‚ ÏƒÎµ PDF (ÎšÏÏÎ¹Î± Î•Ï„Î±Î¹ÏÎµÎ¯Î±)",
            data=pdf_bytes_fixed, 
            file_name=f"Report_{source_name}_{start_year}-{end_year}.pdf",
            mime="application/pdf",
            key="download_pdf_main"
        )

    # --- Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· ---
    st.header(f"Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¹ÎºÏ„ÏÎ½ (Î“Î¹Î± {start_year} - {end_year})")
    
    if not all_ratios_categories.get(main_ticker):
        st.warning("Î”ÎµÎ½ Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚ Î³Î¹Î± Ï„Î·Î½ ÎšÏÏÎ¹Î± Î•Ï„Î±Î¹ÏÎµÎ¯Î±.")
        
    else:
        tab_names = list(all_ratios_categories[main_ticker].keys())
        tabs = st.tabs(tab_names)
        
        for i, tab_name in enumerate(tab_names):
            with tabs[i]:
                st.subheader(f"Î£ÏÎ³ÎºÏÎ¹ÏƒÎ·: {tab_name}")
                
                # v2.3: Î›Î¿Î³Î¹ÎºÎ® Î³Î¹Î± Ï€Î¿Î»Î»Î­Ï‚ ÎµÏ„Î±Î¹ÏÎµÎ¯ÎµÏ‚ + INDUSTRY_AVG
                all_tickers_in_tab = [main_ticker] + selected_peers
                if industry_avg_available:
                    all_tickers_in_tab.append(INDUSTRY_AVG_TICKER)
                
                melted_dfs = []
                valid_ratios_in_tab = set() 
                
                if main_ticker in all_ratios_categories and tab_name in all_ratios_categories[main_ticker]:
                     main_df = all_ratios_categories[main_ticker][tab_name]
                     if not main_df.empty:
                          valid_ratios_in_tab.update(main_df.columns.drop('Year'))
                
                for ticker in all_tickers_in_tab:
                    if ticker in all_ratios_categories and tab_name in all_ratios_categories[ticker]:
                        df = all_ratios_categories[ticker][tab_name]
                        if not df.empty and 'Year' in df.columns:
                            melted_dfs.append(df.melt(id_vars=['Year'], var_name='Ratio', value_name=ticker))
                
                if not melted_dfs:
                    st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± {tab_name}.")
                    continue

                # Î•Î½ÏÎ½Î¿Ï…Î¼Îµ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Ï€Î¯Î½Î±ÎºÎµÏ‚
                try:
                    df_merged = melted_dfs[0]
                    if len(melted_dfs) > 1:
                        for j in range(1, len(melted_dfs)):
                            df_merged = pd.merge(df_merged, melted_dfs[j], on=['Year', 'Ratio'], how='outer')
                    
                    df_merged = df_merged.sort_values(by=['Ratio', 'Year'], ascending=[True, False])
                    st.dataframe(df_merged.set_index('Ratio'), width=1200)
                except Exception as e:
                    st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ ÏƒÏ…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ¿Ï Ï€Î¯Î½Î±ÎºÎ±: {e}")
                
                # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î“ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½ (Î­Î½Î± Î³Î¹Î± ÎºÎ¬Î¸Îµ Î´ÎµÎ¯ÎºÏ„Î·)
                for ratio in valid_ratios_in_tab:
                    st.subheader(f"Î•Î¾Î­Î»Î¹Î¾Î·: {ratio}")
                    
                    chart_data_list = []
                    for ticker in all_tickers_in_tab:
                        if ticker in all_ratios_categories and tab_name in all_ratios_categories[ticker]:
                            df = all_ratios_categories[ticker][tab_name]
                            if ratio in df.columns:
                                chart_data_list.append(df[['Year', ratio]].rename(columns={ratio: ticker}))
                    
                    if not chart_data_list:
                        st.info(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Ï„Î¿ Î³ÏÎ¬Ï†Î·Î¼Î± Ï„Î¿Ï… {ratio}.")
                        continue
                        
                    chart_df = chart_data_list[0]
                    if len(chart_data_list) > 1:
                          for j in range(1, len(chart_data_list)):
                                chart_df = pd.merge(chart_df, chart_data_list[j], on='Year', how='outer')
                    
                    st.line_chart(chart_df.set_index('Year'))

    st.success("âœ… Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
    
    with st.expander("Î”ÎµÏ‚ Ï„Î¿Î½ 'Î§ÏÏ…ÏƒÏŒ' Î Î¯Î½Î±ÎºÎ± (ÎšÏÏÎ¹Î± Î•Ï„Î±Î¹ÏÎµÎ¯Î± - Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ•ÎÎ‘)"):
        st.dataframe(all_company_dfs_analyzed.get(main_ticker, pd.DataFrame()))
        
    for peer_ticker in selected_peers:
        with st.expander(f"Î”ÎµÏ‚ Ï„Î¿Î½ 'Î§ÏÏ…ÏƒÏŒ' Î Î¯Î½Î±ÎºÎ± ({peer_ticker} - Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ•ÎÎ‘)"):
            st.dataframe(all_company_dfs_analyzed.get(peer_ticker, pd.DataFrame()))
    
    # v2.3: Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Debug Î³Î¹Î± Ï„Î¿Î½ ÎœÎ­ÏƒÎ¿ ÎŒÏÎ¿
    if industry_avg_available:
        with st.expander("Î”ÎµÏ‚ Ï„Î¿Ï…Ï‚ 'Î§ÏÏ…ÏƒÎ¿ÏÏ‚' Î Î¯Î½Î±ÎºÎµÏ‚ (ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ ÎšÎ»Î¬Î´Î¿Ï…)"):
            avg_ratios = all_ratios_categories.get(INDUSTRY_AVG_TICKER, {})
            if not avg_ratios:
                st.info("Î”ÎµÎ½ Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚ ÎœÎ­ÏƒÎ¿Ï… ÎŒÏÎ¿Ï….")
            else:
                for category, df in avg_ratios.items():
                    st.caption(f"Î Î¯Î½Î±ÎºÎ±Ï‚: {category} (Îœ.ÎŸ.)")
                    st.dataframe(df)

    with st.expander("Î”ÎµÏ‚ Ï„Î·Î½ Î‘Î½Î±Ï†Î¿ÏÎ¬ Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï (Debug Report - ÎšÏÏÎ¹Î± Î•Ï„Î±Î¹ÏÎµÎ¯Î±)"):
        if main_ticker in all_debug_tables:
            for title, df in all_debug_tables[main_ticker].items():
                st.caption(f"Î Î¯Î½Î±ÎºÎ±Ï‚: {title}")
                st.dataframe(df)
        else:
            st.info("Î”ÎµÎ½ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
            
    for peer_ticker in selected_peers:
         with st.expander(f"Î”ÎµÏ‚ Ï„Î·Î½ Î‘Î½Î±Ï†Î¿ÏÎ¬ Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Ï (Debug Report - {peer_ticker})"):
            if peer_ticker in all_debug_tables:
                for title, df in all_debug_tables[peer_ticker].items():
                    st.caption(f"Î Î¯Î½Î±ÎºÎ±Ï‚: {title}")
                    st.dataframe(df)

else:
    st.info("Î•Ï€Î¯Î»ÎµÎ¾Îµ Ï€Î·Î³Î® ÎºÎ±Î¹ ÎµÏ„Î±Î¹ÏÎµÎ¯Î± Î±Ï€ÏŒ Ï„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ± Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹Ï‚.")