# test_loader.py (v3.6 - Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· "Î§ÏÏÎ±Ï‚")
import os
import sys
import pandas as pd
import yfinance as yf
import requests
from typing import Optional, Tuple, List, Dict, Any
import re 
import io

# === === === === === === === === ===
# === ÎŸ ÎÎ•ÎŸÎ£ ÎœÎ‘Î£ ÎšÎ™ÎÎ—Î¤Î—Î¡Î‘Î£ F1 ===
from unstructured.partition.pdf import partition_pdf
from unstructured.documents.elements import Title, NarrativeText, Text, Table, Element
# === === === === === === === === ===

# (Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Ï„Î¿Î½ Î³Î¿Î½Î¹ÎºÏŒ Ï†Î¬ÎºÎµÎ»Î¿ ÏƒÏ„Î¿ path Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï„Î¿ 'modules')
try:
    base_dir = os.path.dirname(os.path.abspath(__file__))
    if 'modules' not in os.listdir(base_dir):
        base_dir = os.path.dirname(base_dir)
    if 'modules' not in os.listdir(base_dir):
        print("Warning: 'modules' folder not found in parent directory.")
    sys.path.append(base_dir)
    from modules.analyzer import calculate_financial_ratios
except ImportError:
    print("âš ï¸ Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ 'modules/analyzer.py'.")
    def calculate_financial_ratios(*args, **kwargs):
        print("DUMMY ANALYZER: Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¸Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹.")
        return {"ratios": pd.DataFrame(), "categories": {}, "sector": "Unknown"}
except FileNotFoundError:
    print("Warning: Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î²ÏÎµÎ¸ÎµÎ¯ Ï„Î¿ path.")
    try:
        from modules.analyzer import calculate_financial_ratios
    except ImportError:
       def calculate_financial_ratios(*args, **kwargs):
            print("DUMMY ANALYZER: Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¸Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹.")
            return {"ratios": pd.DataFrame(), "categories": {}, "sector": "Unknown"}


# -----------------------------
# ğŸ”¹ Column Normalization Map (Yahoo) - v1.4
# -----------------------------
YAHOO_COLUMN_MAP = {
    'Total Revenue': 'Revenue', 'Revenue': 'Revenue', 'Cost of Revenue': 'CostOfGoodsSold', 
    'Cost Of Revenue': 'CostOfGoodsSold', 'COGS': 'CostOfGoodsSold', 'Gross Profit': 'GrossProfit',
    'Operating Income': 'OperatingIncome', 'Operating Profit': 'OperatingIncome', 'Net Income': 'NetIncome',
    'Total Current Assets': 'CurrentAssets', 'Current Assets': 'CurrentAssets', 'Total Assets': 'TotalAssets',
    'Assets': 'TotalAssets', 'Cash': 'Cash', 'Cash and Cash Equivalents': 'Cash',
    'Cash And Cash Equivalents': 'Cash', 'Inventory': 'Inventory', 'Inventories': 'Inventory',
    'Total Current Liabilities': 'CurrentLiabilities', 'Current Liabilities': 'CurrentLiabilities',
    'Total Liabilities': 'TotalLiabilities', 'Total Liab': 'TotalLiabilities', 'Total Debt': 'TotalDebt', 
    'Total Equity': 'TotalEquity', 'Shareholders Equity': 'TotalEquity', 'StockholdersEquity': 'TotalEquity',
    'Stockholders Equity': 'TotalEquity', 'Stockholder Equity': 'TotalEquity', 
    'Total Stockholder Equity': 'TotalEquity', 'Total Stockholders Equity': 'TotalEquity', 
    'Common Stock Equity': 'TotalEquity',
    'Total Cash From Operating Activities': 'OperatingCashFlow', 'Operating Cash Flow': 'OperatingCashFlow',
    'Shares Outstanding': 'SharesOutstanding', 'Total Loans': 'Loans', 'Total Deposits': 'Deposits', 
    'Net Interest Income': 'NetInterestIncome', 'Average Earning Assets': 'AverageEarningAssets', 
    'Research And Development': 'R&D', 'R&D Expenses': 'R&D', 'Oil Production': 'OilProduction', 
    'Gas Production': 'GasProduction', 'Operating Expenses': 'OperatingExpenses',
}


# -----------------------------
# ğŸ”¹ Column Normalization Map (Generic) - v1.5
# -----------------------------
GENERIC_FILE_MAP = {
    # (Î‘Ï…Ï„ÏŒÏ‚ Î¿ Ï‡Î¬ÏÏ„Î·Ï‚ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ *Î¼ÎµÏ„Î¬* Ï„Î¿ "Pivot")
    'Total Revenue': 'Revenue', 'Revenue': 'Revenue', 'Sales': 'Revenue', 'Turnover': 'Revenue', 'ÎˆÏƒÎ¿Î´Î±': 'Revenue',
    'Cost of Revenue': 'CostOfGoodsSold', 'COGS': 'CostOfGoodsSold', 'Cost of Sales': 'CostOfGoodsSold',
    'Gross Profit': 'GrossProfit', 'Gross Income': 'GrossProfit',
    'Operating Income': 'OperatingIncome', 'Operating Profit': 'OperatingIncome',
    'Net Income': 'NetIncome', 'Profit After Tax': 'NetIncome', 'ÎšÎ±Î¸Î±ÏÎ¬ ÎšÎ­ÏÎ´Î·': 'NetIncome',
    'Total Current Assets': 'CurrentAssets', 'Current Assets': 'CurrentAssets',
    'Total Current Liabilities': 'CurrentLiabilities', 'Current Liabilities': 'CurrentLiabilities',
    'Total Assets': 'TotalAssets', 'Assets': 'TotalAssets', 'Î•Î½ÎµÏÎ³Î·Ï„Î¹ÎºÏŒ': 'TotalAssets',
    'Total Liabilities': 'TotalLiabilities', 'Total Liab': 'TotalLiabilities', 'Total Debt': 'TotalDebt', 'Debt': 'TotalDebt', 'Î¥Ï€Î¿Ï‡ÏÎµÏÏƒÎµÎ¹Ï‚': 'TotalLiabilities',
    'Total Equity': 'TotalEquity', 'Shareholders Equity': 'TotalEquity', 'StockholdersEquity': 'TotalEquity',
    'Total Stockholder Equity': 'TotalEquity', 'Stockholder Equity': 'TotalEquity', 'Total Stockholders Equity': 'TotalEquity', 
    'Common Stock Equity': 'TotalEquity', 'Stockholders Equity': 'TotalEquity', 
    'Cash': 'Cash', 'Cash and Cash Equivalents': 'Cash', 'Cash And Cash Equivalents': 'Cash',
    'Inventory': 'Inventory', 'Inventories': 'Inventory',
    'Shares Outstanding': 'SharesOutstanding', 'Basic Shares Outstanding': 'SharesOutstanding',
    'Total Cash From Operating Activities': 'OperatingCashFlow', 'Operating Cash Flow': 'OperatingCashFlow',
    'Total Loans': 'Loans', 'Loans': 'Loans', 'Total Deposits': 'Deposits', 'Deposits': 'Deposits',
    'Net Interest Income': 'NetInterestIncome', 'Average Earning Assets': 'AverageEarningAssets',
    'Research And Development': 'R&D', 'R&D Expenses': 'R&D',
}

def normalize_dataframe(df: pd.DataFrame, source_type: str) -> pd.DataFrame:
    """
    "ÎŸ ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®Ï‚"
    Î Î±Î¯ÏÎ½ÎµÎ¹ Î­Î½Î±Î½ *Î¼ÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î¿*, ÏƒÏ‡ÎµÎ´ÏŒÎ½-ÎºÎ±Î¸Î±ÏÏŒ Ï€Î¯Î½Î±ÎºÎ± (Ï€.Ï‡. Î™ÏƒÎ¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ)
    ÎºÎ±Î¹ Ï„Î¿Î½ "Î³Ï…ÏÎ½Î¬ÎµÎ¹" (Pivot) ÏÏƒÏ„Îµ Î¿Î¹ Ï‡ÏÎ¿Î½Î¹Î­Ï‚ Î½Î± Î³Î¯Î½Î¿Ï…Î½ ÏƒÏ„Î®Î»ÎµÏ‚.
    """
    if df.empty:
        return df

    if source_type == "yahoo":
        mapping = YAHOO_COLUMN_MAP
    elif source_type in ["csv", "excel", "pdf"]:
        mapping = GENERIC_FILE_MAP
    else:
        print(f"âš ï¸ Warning: Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ source_type '{source_type}'. Î§ÏÎ®ÏƒÎ· 'GENERIC_FILE_MAP'.")
        mapping = GENERIC_FILE_MAP

    normalized_df = pd.DataFrame()
    
    # === PDF SPECIAL HANDLING (v3.0) ===
    # Î‘Ï…Ï„Î® Î· Î»Î¿Î³Î¹ÎºÎ® "Pivot" Î¸Î± Ï„ÏÎ­Î¾ÎµÎ¹ Î¼ÏŒÎ½Î¿ Î³Î¹Î± PDF (ÎºÎ±Î¹ CSV)
    # v3.5: Î¤ÏÏÎ± Ï„ÏÎ­Ï‡ÎµÎ¹ ÎœÎŸÎÎŸ Î³Î¹Î± PDF
    if source_type == "pdf" or (source_type in ["csv", "excel"] and 'Year' not in df.columns and 'Date' not in df.columns):
        print(f"  [Normalize] -> Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎµ {source_type}. Î•ÎºÏ„Î­Î»ÎµÏƒÎ· 'Pivot'...")
        try:
            # 1. Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± (Ï€.Ï‡. 'Total Assets')
            # (ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± Î±Ï€ÏŒ Ï„Ï…Ï‡ÏŒÎ½ NaN Ï€Î¿Ï… Î­Î³Î¹Î½Î±Î½ string)
            label_col = str(df.columns[0]).strip()
            if label_col == "" or label_col.lower() == "nan" or label_col.lower().startswith("unnamed"):
                # Î‘Î½ Î· Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· ÎµÎ¯Î½Î±Î¹ Î¬Ï‡ÏÎ·ÏƒÏ„Î·, Î´Î¿ÎºÎ¹Î¼Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î· Î´ÎµÏÏ„ÎµÏÎ·
                print(f"  [Normalize] -> Warning: Î— Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· '{label_col}' ÎµÎ¯Î½Î±Î¹ Î¬Ï‡ÏÎ·ÏƒÏ„Î·. Î”Î¿ÎºÎ¹Î¼Î® Ï„Î·Ï‚ 2Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚.")
                label_col = str(df.columns[1]).strip()
                if label_col == "" or label_col.lower() == "nan" or label_col.lower().startswith("unnamed"):
                    print("  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î®Î»Î· Î³Î¹Î± Ï„Î± labels.")
                    return pd.DataFrame()
            
            # 2. Î¤Î· Î¸Î­Ï„Î¿Ï…Î¼Îµ Ï‰Ï‚ Index
            # v3.5 Fix: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½ ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ (Ï€.Ï‡. 'Total', 'Total')
            if df[label_col].duplicated().any():
                # Î”Î¯Î½Î¿Ï…Î¼Îµ Î¼Î¿Î½Î±Î´Î¹ÎºÎ¬ Î¿Î½ÏŒÎ¼Î±Ï„Î± (Ï€.Ï‡. 'Total', 'Total_2')
                df[label_col] = df[label_col].astype(str).str.strip()
                
                # (v3.6) Î Î¹Î¿ Î±Ï€Î»Î® Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· Î³Î¹Î± Î¼Î¿Î½Î±Î´Î¹ÎºÏŒÏ„Î·Ï„Î±
                df[label_col] = df.groupby(label_col).cumcount().astype(str) + '_' + df[label_col]
                df[label_col] = df[label_col].str.replace('0_', '', n=1) # Î‘Î½Ï„Î¹ÎºÎ±Î¸Î¹ÏƒÏ„Î¬ Ï„Î¿ Ï€ÏÏÏ„Î¿ '0_Total' -> 'Total'
                
            df = df.set_index(label_col)
            
            # 3. "Î“Ï…ÏÎ½Î¬Î¼Îµ" (Transpose) Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ±
            df = df.T
            
            # 4. Î•Ï€Î±Î½Î±Ï†Î­ÏÎ¿Ï…Î¼Îµ Ï„Î¿ index (Ï€Î¿Ï… Ï„ÏÏÎ± Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Ï‡ÏÎ¿Î½Î¹Î­Ï‚/Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚)
            df = df.reset_index()
            
            # 5. Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î¿ 'Year'
            year_col = str(df.columns[0]) # Î¥Ï€Î¿Î¸Î­Ï„Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ ÎµÎ¯Î½Î±Î¹ Î· Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î·
            
            # Î’ÏÎ¯ÏƒÎºÎµÎ¹ 4-ÏˆÎ®Ï†Î¹Î¿ Î±ÏÎ¹Î¸Î¼ÏŒ Ï€Î¿Ï… *Î´ÎµÎ½* ÎµÎ¯Î½Î±Î¹ Î¼Î­ÏƒÎ± ÏƒÎµ $
            df['Year'] = df[year_col].astype(str).str.extract(r'(?<!\d\s)(\d{4})(?!\d)')
            
            df = df.dropna(subset=['Year']) # Î Î­Ï„Î±Î¾Îµ Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï‡ÏÎ¿Î½Î¹Î­Ï‚
            if df.empty:
                print(f"  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï‡ÏÎ¿Î½Î¹Î­Ï‚ ÏƒÏ„Î¿ header (ÏƒÏ„Î®Î»Î· '{year_col}').")
                return pd.DataFrame()

            print(f"  [Normalize] -> 'Pivot' ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚.")
        except Exception as e:
            print(f"  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame() # Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î±
    
    elif source_type == "yahoo":
         df = df # (ÎŸ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ‰ÏƒÏ„ÏŒÏ‚)
    
    # v3.6: Î•Î¹Î´Î¹ÎºÏŒÏ‚ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î³Î¹Î± CSV/Excel Ï€Î¿Ï… *Î­Ï‡Î¿Ï…Î½* Ï‡ÏÎ¿Î½Î¹Î¬
    elif source_type in ["csv", "excel"]:
        if 'Year' not in df.columns and 'Date' in df.columns:
            df['Year'] = pd.to_datetime(df['Date']).dt.year
        df = df # (ÎŸ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ‰ÏƒÏ„ÏŒÏ‚)


    # (ÎŸ Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î¿Ï‚ ÎºÏÎ´Î¹ÎºÎ±Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î¯Î´Î¹Î¿Ï‚ Î¼Îµ Ï€ÏÎ¹Î½)
    for col in ['Year', 'Date']:
        if col in df.columns and col not in normalized_df.columns:
            normalized_df[col] = df[col]

    # ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± ÏƒÏ„Î·Î»ÏÎ½ (Ï€.Ï‡. Î±Ï†Î±Î¯ÏÎµÏƒÎ· \n) *Ï€ÏÎ¹Î½* Ï„Î¿ mapping
    df.columns = [str(col).replace('\n', ' ').strip() for col in df.columns]
    df_columns_stripped = {str(col).strip(): col for col in df.columns}
        
    for source_col, standard_col in mapping.items():
        matching_source_col = None
        
        # ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ source_col (Î±Ï€ÏŒ Ï„Î¿ MAP) Î³Î¹Î± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
        source_col_clean = str(source_col).strip()
        
        # 1. Î‘Ï€Î»Î® Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· (Ï€.Ï‡. 'Total Assets' == 'Total Assets')
        if source_col_clean in df_columns_stripped:
            matching_source_col = df_columns_stripped[source_col_clean]
        
        # 2. Î‘Î½ Î´ÎµÎ½ Î²ÏÎµÎ¸ÎµÎ¯, ÎºÎ¬Î½Î¿Ï…Î¼Îµ lower-case ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
        elif source_type in ["csv", "excel", "pdf", "yahoo"]: # v3.6: Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Yahoo
            source_col_lower = source_col_clean.lower()
            for df_col_stripped, df_col_original in df_columns_stripped.items():
                if df_col_stripped.lower() == source_col_lower:
                    matching_source_col = df_col_original
                    break

        if matching_source_col:
            if standard_col not in normalized_df.columns:
                # ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚
                # v3.4: Î•Ï†Î±ÏÎ¼Î¿Î³Î® Ï„Î¿Ï… clean_value_unstructured ÎšÎ‘Î™ ÎµÎ´Ï
                clean_col = pd.to_numeric(df[matching_source_col].astype(str).map(clean_value_unstructured), errors='coerce')
                normalized_df[standard_col] = clean_col

    if 'TotalLiabilities' not in normalized_df.columns and 'TotalDebt' in normalized_df.columns:
        normalized_df['TotalLiabilities'] = normalized_df['TotalDebt']
        print("  [Normalize] Info: 'TotalLiabilities' not found. Using 'TotalDebt' as a proxy.")

    return normalized_df

# -----------------------------
# ğŸ”¹ Utilities: (Search, Premium, ÎºÎ»Ï€.)
# -----------------------------
YAHOO_SEARCH_URL = "https://query2.finance.yahoo.com/v1/finance/search"

def search_company_by_name(name: str, limit: int = 10):
    try:
        params = {"q": name, "quotesCount": limit, "newsCount": 0}
        r = requests.get(YAHOO_SEARCH_URL, params=params, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        data = r.json()
        results = []
        for item in data.get("quotes", []):
            results.append({
                "symbol": item.get("symbol"),
                "name": item.get("shortname") or item.get("longname") or item.get("displayName") or item.get("name"),
                "exchange": item.get("exchange"),
                "type": item.get("typeDisp")
            })
        return results
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ search: {e}")
        return []

def resolve_to_ticker(user_input: str, source_type: str = "yahoo") -> Optional[str]:
    candidate = user_input.strip()
    
    print(f"Info: Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± '{candidate}'...")
    matches = search_company_by_name(candidate, limit=10)
    
    is_streamlit = 'streamlit' in sys.modules
    if not matches:
        if is_streamlit:
            print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚.")
            return None
        else:
            print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚.")
            return None
    
    if is_streamlit:
        print(f"Info: Î’ÏÎ­Î¸Î·ÎºÎµ '{matches[0]['symbol']}' Î³Î¹Î± Ï„Î¿ '{candidate}'.")
        return matches[0]['symbol']
    
    print("\nÎ’ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚:")
    for i, m in enumerate(matches, start=1):
        name = m.get("name") or "â€”"; symbol = m.get("symbol") or "â€”"
        exch = m.get("exchange") or ""; typ = m.get("type") or ""
        print(f"{i}. {name} ({symbol}) {exch} {typ}")
    sel = input("Î•Ï€Î­Î»ÎµÎ¾Îµ Î±ÏÎ¹Î¸Î¼ÏŒ Ï„Î·Ï‚ ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Î® Î¬ÏƒÎµ ÎºÎµÎ½ÏŒ Î³Î¹Î± Î±ÎºÏÏÏ‰ÏƒÎ·): ").strip()
    try:
        if sel == "": return None
        sel_i = int(sel) - 1
        if 0 <= sel_i < len(matches):
            return matches[sel_i]["symbol"]
        else:
            print("ÎœÎ· Î­Î³ÎºÏ…ÏÎ· ÎµÏ€Î¹Î»Î¿Î³Î®."); return None
    except Exception:
        print("ÎœÎ· Î­Î³ÎºÏ…ÏÎ· ÎµÎ¯ÏƒÎ¿Î´Î¿Ï‚ (ÎŠÏƒÏ‰Ï‚ Î­Î´Ï‰ÏƒÎµÏ‚ Ticker Î±Î½Ï„Î¯ Î³Î¹Î± Î‘ÏÎ¹Î¸Î¼ÏŒ;)."); return None

def get_premium_data(ticker: str, api_key: Optional[str] = None, source: str = "premium") -> pd.DataFrame:
    # (Placeholder)
    return pd.DataFrame()


# -----------------------------
# ğŸ”¹ PDF Data Extractor (v3.5 - ÎŸ "ÎšÏ…Î½Î·Î³ÏŒÏ‚" ÎšÎ»ÎµÎ¹Î´Î¹ÏÎ½)
# -----------------------------

# Î›Î­Î¾ÎµÎ¹Ï‚-ÎºÎ»ÎµÎ¹Î´Î¹Î¬ Ï€Î¿Ï… Î¿ÏÎ¯Î¶Î¿Ï…Î½ Î­Î½Î±Î½ "ÎšÏÏÎ¹Î¿ Î¤Î¯Ï„Î»Î¿", Î±ÎºÏŒÎ¼Î± ÎºÎ¹ Î±Î½ Ï„Î¿ AI Ï„Î± Î¼Ï€ÎµÏÎ´Î­ÏˆÎµÎ¹
# v3.5: ÎŸ "ÎšÏ…Î½Î·Î³ÏŒÏ‚" ÎšÎ»ÎµÎ¹Î´Î¹ÏÎ½
MAIN_TITLE_KEYWORDS = [
    'balance sheet', 'Î¹ÏƒÎ¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ïƒ', 'financial position',
    'income statement', 'ÎºÎ±Ï„Î±ÏƒÏ„Î±ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Ï‰Î½', 'results of operations',
    'cash flow', 'Ï„Î±Î¼ÎµÎ¹Î±ÎºÎµÏƒ ÏÎ¿ÎµÏƒ'
]

def is_subtitle(text: str) -> bool:
    """
    v3.5: Î•Î»Î­Î³Ï‡ÎµÎ¹ Î±Î½ Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Î¿Î¹Î¬Î¶ÎµÎ¹ Î¼Îµ "Ï…Ï€ÏŒÏ„Î¹Ï„Î»Î¿" (Ï€.Ï‡. "(In millions)")
    Î±Î»Î»Î¬ Î”Î•Î ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ ÎºÏÏÎ¹Î¿Ï…Ï‚ Ï„Î¯Ï„Î»Î¿Ï…Ï‚.
    """
    text_clean = text.strip()
    if not text_clean or len(text_clean) == 0:
        return False
        
    # v3.5: Î‘Î½ ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ ÎšÎ¥Î¡Î™ÎŸÎ¥Î£ Ï„Î¯Ï„Î»Î¿Ï…Ï‚, Î”Î•Î ÎµÎ¯Î½Î±Î¹ Ï…Ï€ÏŒÏ„Î¹Ï„Î»Î¿Ï‚
    text_lower = text_clean.lower()
    if any(key in text_lower for key in MAIN_TITLE_KEYWORDS):
        return False
        
    is_short = len(text_clean) < 100
    not_sentence = not text_clean.endswith('.')
    is_header_like = (
        text_clean.startswith(('(', '$')) or
        text_clean.endswith(':') or
        text_clean.isupper() or
        bool(re.match(r'^\(?\s*In millions', text_clean, re.IGNORECASE)) or
        bool(re.match(r'^\s*\d{4}\s*$', text_clean)) # "2023"
    )
    
    return is_short and not_sentence and is_header_like

def clean_value_unstructured(val):
    """ 
    ÎšÎ±Î¸Î±ÏÎ¹ÏƒÏ„Î®Ï‚ ÎµÎ¹Î´Î¹ÎºÎ¬ Î³Î¹Î± Ï„Î¿ output Ï„Î¿Ï… unstructured.
    (Î¤ÏÏÎ± ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ ÎºÎ±Î¹ Î±Ï€ÏŒ Ï„Î¿ normalize_dataframe)
    """
    if val is None: return pd.NA
    s = str(val).strip()
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î½Î¿Î¼Î¹ÏƒÎ¼Î¬Ï„Ï‰Î½, commmas, ÎºÎ±Î¹ Î³ÏÎ±Î¼Î¼ÏÎ½
    s = s.replace('$', '').replace(',', '').replace('â€”', '0').replace('â‚¬', '').replace('Â£', '')
    
    # Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±ÏÎ½Î·Ï„Î¹ÎºÏÎ½ (Ï€.Ï‡. "(1,234.5)")
    if s.startswith('(') and s.endswith(')'):
        s = '-' + s[1:-1]
        
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Ï…Ï‡ÏŒÎ½ " (1)" Î® "[2]" (references)
    s = re.sub(r'\s*[\(\[]\d+[\)\]]', '', s) 
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Ï…Ï‡ÏŒÎ½ " %"
    s = s.replace('%', '')
    
    # Î‘Î½ Î¼ÎµÎ¯Î½ÎµÎ¹ ÎºÎµÎ½ÏŒ, ÎµÎ¯Î½Î±Î¹ 0 (Î® ÎÎ‘ Î³Î¹Î± Î½Î± Î¼Î·Î½ ÏƒÏ€Î¬ÏƒÎµÎ¹ Ï„Î¿ numeric)
    if s == "":
        return pd.NA
        
    return s

def sanitize_columns(df_to_fix):
    """ÎœÎµÏ„Î¿Î½Î¿Î¼Î¬Î¶ÎµÎ¹ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ (Ï€.Ï‡. 'Amount', 'Amount_2')"""
    if df_to_fix.empty:
        return df_to_fix
        
    new_cols = []
    col_counts = {}
    
    # v3.4 Fix: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ MultiIndex (Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ Î´Î¹Ï€Î»Î¬ headers)
    if df_to_fix.columns.nlevels > 1:
        print("   -> Warning: Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎµ MultiIndex, Î±Ï€Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·...")
        # Î•Î½ÏÎ½ÎµÎ¹ Ï„Î± ÎµÏ€Î¯Ï€ÎµÎ´Î±, Ï€.Ï‡. ('Revenue', '2023') -> 'Revenue_2023'
        df_to_fix.columns = ['_'.join(map(str, col)).strip().replace(r'Unnamed: \d+_level_\d_', '', regex=True) for col in df_to_fix.columns.values]

    for col in df_to_fix.columns:
        if not isinstance(col, str):
            col = str(col) if col is not None else "Unnamed"
        
        # v3.4 Fix: Î‘Ï†Î±Î¯ÏÎµÏƒÎ· "Unnamed" Î±Ï€ÏŒ headers
        col = re.sub(r'Unnamed: \d+', '', col).strip()
        
        if col in col_counts:
            col_counts[col] += 1
            new_col_name = f"{col}_{col_counts[col]}" # Ï€.Ï‡. "Amount_2"
        else:
            col_counts[col] = 1
            new_col_name = col
        
        # v3.4 Fix: Î‘Î½ Î· ÏƒÏ„Î®Î»Î· Î¼ÎµÎ¯Î½ÎµÎ¹ Ï„ÎµÎ»ÎµÎ¯Ï‰Ï‚ ÎºÎµÎ½Î®, Î´ÏÏƒÎµ Ï„Î·Ï‚ Î­Î½Î± ÏŒÎ½Î¿Î¼Î±
        if new_col_name == "":
            new_col_name = f"Unnamed_{col_counts.get('', 0)}"
            col_counts[''] = col_counts.get('', 0) + 1
            
        new_cols.append(new_col_name)
    
    df_to_fix.columns = new_cols
    return df_to_fix


def load_data_from_pdf(file_path: str) -> List[Dict[str, Any]]:
    """
    v3.5: ÎŸ "ÎšÏ…Î½Î·Î³ÏŒÏ‚" ÎšÎ»ÎµÎ¹Î´Î¹ÏÎ½.
    Î£Î±ÏÏÎ½ÎµÎ¹ Ï„Î¿ PDF ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼Î¹Î± Î›Î™Î£Î¤Î‘ Î±Ï€ÏŒ "Ï€Î±ÎºÎ­Ï„Î±" (Ï„Î¯Ï„Î»Î¿Ï‚ + Ï€Î¯Î½Î±ÎºÎ±Ï‚).
    """
    print(f"ğŸ“„ ÎˆÎ½Î±ÏÎ¾Î· Î­Î¾Ï…Ï€Î½Î·Ï‚ ÏƒÎ¬ÏÏ‰ÏƒÎ·Ï‚ PDF (v3.5 - F1 Engine): {file_path}")
    
    all_data = []
    current_main_title = "Untitled" # ÎŸ ÎšÏÏÎ¹Î¿Ï‚ Î¤Î¯Ï„Î»Î¿Ï‚ (Ï€.Ï‡. "INCOME STATEMENTS")
    current_subtitle = ""    # ÎŸ Î¥Ï€ÏŒÏ„Î¹Ï„Î»Î¿Ï‚ (Ï€.Ï‡. "(In millions)")

    try:
        # 1. ÎŸ "ÎšÎ¹Î½Î·Ï„Î®ÏÎ±Ï‚ F1" ÏƒÎ±ÏÏÎ½ÎµÎ¹ Ï„Î¿ PDF
        elements = partition_pdf(
            file_path, 
            strategy="hi_res", 
            infer_table_structure=True
        )

        # 2. v3.5: "Î Î±Î½Ï„ÏÎµÏÎ¿Ï…Î¼Îµ" Î¤Î¯Ï„Î»Î¿Ï…Ï‚ ÎºÎ±Î¹ Î Î¯Î½Î±ÎºÎµÏ‚
        for el in elements:
            
            # v3.5: ÎŸ "ÎšÏ…Î½Î·Î³ÏŒÏ‚" ÎšÎ»ÎµÎ¹Î´Î¹ÏÎ½
            # (Î‘Î½Î±Î²Î±Î¸Î¼Î¯Î¶ÎµÎ¹ Î­Î½Î± "Text" ÏƒÎµ "ÎšÏÏÎ¹Î¿ Î¤Î¯Ï„Î»Î¿" Î±Î½ Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹)
            is_main_title_from_text = False
            if isinstance(el, (Text, NarrativeText)):
                text_lower = el.text.strip().lower()
                if any(key in text_lower for key in MAIN_TITLE_KEYWORDS):
                    current_main_title = el.text.strip()
                    current_subtitle = "" # ÎšÎ¬Î½Î¿Ï…Î¼Îµ reset Ï„Î¿Î½ Ï…Ï€ÏŒÏ„Î¹Ï„Î»Î¿
                    print(f"  > (Debug) Î’ÏÎ­Î¸Î·ÎºÎµ ÎšÎ¥Î¡Î™ÎŸÎ£ Î¤Î¯Ï„Î»Î¿Ï‚ (Î±Ï€ÏŒ ÎšÎµÎ¯Î¼ÎµÎ½Î¿): '{current_main_title}'")
                    is_main_title_from_text = True
            
            # === === === === ===
            
            if isinstance(el, Title):
                current_main_title = el.text.strip()
                current_subtitle = "" # ÎšÎ¬Î½Î¿Ï…Î¼Îµ reset Ï„Î¿Î½ Ï…Ï€ÏŒÏ„Î¹Ï„Î»Î¿
                print(f"  > (Debug) Î’ÏÎ­Î¸Î·ÎºÎµ ÎšÎ¥Î¡Î™ÎŸÎ£ Î¤Î¯Ï„Î»Î¿Ï‚: '{current_main_title}'")
            
            elif isinstance(el, Text) and not is_main_title_from_text:
                # Î‘Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎšÏÏÎ¹Î¿Ï‚ Î¤Î¯Ï„Î»Î¿Ï‚, Î¯ÏƒÏ‰Ï‚ ÎµÎ¯Î½Î±Î¹ Î¥Ï€ÏŒÏ„Î¹Ï„Î»Î¿Ï‚;
                if is_subtitle(el.text):
                    current_subtitle = el.text.strip()
                    print(f"  > (Debug) Î’ÏÎ­Î¸Î·ÎºÎµ ÎšÎµÎ¯Î¼ÎµÎ½Î¿-Î¥Ï€ÏŒÏ„Î¹Ï„Î»Î¿Ï‚: '{current_subtitle}'")
            
            elif isinstance(el, Table):
                # Î’Î¡Î—ÎšÎ‘ÎœÎ• Î Î™ÎÎ‘ÎšÎ‘! Î‘Ï‚ Ï„Î¿Î½ "Ï€Î±Î½Ï„ÏÎ­ÏˆÎ¿Ï…Î¼Îµ".
                if current_subtitle:
                    full_title = f"{current_main_title} - {current_subtitle}"
                else:
                    full_title = current_main_title
                
                print(f"  > Î’ÏÎ­Î¸Î·ÎºÎµ Î Î¯Î½Î±ÎºÎ±Ï‚ (ML) (Î‘Î½Î®ÎºÎµÎ¹ ÏƒÏ„Î¿Î½ Ï„Î¯Ï„Î»Î¿: '{full_title}')...")
                
                html_table = getattr(el.metadata, 'text_as_html', None)
                if not html_table:
                    print("  -> Warning: Î’ÏÎ­Î¸Î·ÎºÎµ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ML, Î±Î»Î»Î¬ Î»ÎµÎ¯Ï€ÎµÎ¹ Ï„Î¿ text_as_html.")
                    continue
                    
                # Î¤Î¿ Pandas Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„Î¿ HTML ÎºÎ±Î¹ Ï„Î¿ ÎºÎ¬Î½ÎµÎ¹ DataFrame
                dfs = pd.read_html(io.StringIO(html_table))
                if not dfs:
                    print("  -> Warning: Î¤Î¿ Pandas Î±Ï€Î­Ï„Ï…Ï‡Îµ Î½Î± Î´Î¹Î±Î²Î¬ÏƒÎµÎ¹ Ï„Î¿ HTML Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ±.")
                    continue
                
                table_df = dfs[0]

                # === ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± (Ï€ÏÎ¹Î½ Ï„Î¿Î½ ÏƒÏ„ÎµÎ¯Î»Î¿Ï…Î¼Îµ) ===
                try:
                    # 1. Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ header
                    header_idx = 0
                    # (Î‘Î½ Î· Ï€ÏÏÏ„Î· Î³ÏÎ±Î¼Î¼Î® ÎµÎ¯Î½Î±Î¹ Ï„ÎµÎ»ÎµÎ¯Ï‰Ï‚ ÎºÎµÎ½Î® Î® Î³ÎµÎ¼Î¬Ï„Î· NaN)
                    if not table_df.empty and table_df.iloc[0].isnull().all(): 
                        header_idx = 1
                    
                    if header_idx >= len(table_df):
                         print(f"  -> Warning: Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Ï€Î¯Î½Î±ÎºÎ± (Ï„Î¯Ï„Î»Î¿Ï‚: {full_title}) - Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ header.")
                         continue

                    new_header = table_df.iloc[header_idx]
                    df_data = table_df.iloc[header_idx+1:]
                    
                    # (ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½Î¬)
                    if df_data.empty:
                        print(f"  -> Warning: Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Ï€Î¯Î½Î±ÎºÎ± (Ï„Î¯Ï„Î»Î¿Ï‚: {full_title}) - Î’ÏÎ­Î¸Î·ÎºÎµ header Î±Î»Î»Î¬ ÏŒÏ‡Î¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
                        continue
                        
                    df_data.columns = new_header
                    
                    # 2. ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚
                    df_clean = df_data.apply(lambda col: col.map(clean_value_unstructured))
                    
                    # 3. Î•Î¾Ï…Î³Î¯Î±Î½ÏƒÎ· ÏƒÏ„Î·Î»ÏÎ½ (Ï€ÏÎ¹Î½ Ï„Î·Î½ Î­Î½Ï‰ÏƒÎ·)
                    df_sanitized = sanitize_columns(df_clean)
                    
                    # 4. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… "Ï€Î±ÎºÎ­Ï„Î¿Ï…"
                    all_data.append({"title": full_title, "table": df_sanitized})

                except Exception as e:
                    print(f"  -> Warning: Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Ï Ï€Î¯Î½Î±ÎºÎ± (Ï„Î¯Ï„Î»Î¿Ï‚: {full_title}): {e}")
                    # (Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î¿ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚, ÏƒÏ„Î­Î»Î½Î¿Ï…Î¼Îµ Ï„Î¿Î½ "Î²ÏÏÎ¼Î¹ÎºÎ¿" Ï€Î¯Î½Î±ÎºÎ±)
                    all_data.append({"title": full_title, "table": table_df})
        
        if not all_data:
            print("âš ï¸ ÎŸ ÎšÎ¹Î½Î·Ï„Î®ÏÎ±Ï‚ F1 (unstructured) Î´ÎµÎ½ Î²ÏÎ®ÎºÎµ Ï€Î¯Î½Î±ÎºÎµÏ‚.")
            return []

        print(f"  Î•Ï€Î¹Ï„Ï…Ï‡Î¯Î±! Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(all_data)} 'Ï€Î±ÎºÎ­Ï„Î±' (Ï„Î¯Ï„Î»Î¿Ï‚/Ï€Î¯Î½Î±ÎºÎ±Ï‚).")
        return all_data

    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î­Î¾Ï…Ï€Î½Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï„Î¿Ï… PDF (v3.5): {e}")
        import traceback
        traceback.print_exc()
        return [] # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÎºÎµÎ½Î®Ï‚ Î»Î¯ÏƒÏ„Î±Ï‚

# -----------------------------
# ğŸ”¹ Loader Î³Î¹Î± Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï€Î·Î³Î­Ï‚
# -----------------------------
def get_company_df(source: str, source_type: str = "yahoo", api_key: Optional[str] = None, period: str = "5y") -> List[Dict[str, Any]]:
    """
    v3.5: Î•Î Î™Î£Î¤Î¡Î•Î¦Î•Î™ Î Î‘ÎÎ¤Î‘ Î›Î™Î£Î¤Î‘ ÎœÎ• "Î Î‘ÎšÎ•Î¤Î‘" [ {"title": ..., "table": ...} ]
    """
    source_type = source_type.lower()

    if source_type == "yahoo":
        print("âš¡ Î›Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Yahoo Finance...")
        # v3.5: Î¤Î¿ Yahoo Î”Î•Î ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î»Î¯ÏƒÏ„Î±. Î¤Î¿ Î¼ÎµÏ„Î±Ï„ÏÎ­Ï€Î¿Ï…Î¼Îµ.
        yahoo_df = get_yahoo_data(source, period=period)
        if yahoo_df.empty:
            return []
        # Î¤Î¿ "Ï€Î±ÎºÎµÏ„Î¬ÏÎ¿Ï…Î¼Îµ" Î³Î¹Î± Î½Î± Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ Î¼Îµ Ï„Î¿ PDF
        return [{"title": "Yahoo Finance Data", "table": yahoo_df}]
        
    elif source_type in ["csv", "excel"]:
        print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ {source_type.upper()}: {source}")
        try:
            if source_type == "csv":
                df = pd.read_csv(source)
            else:
                df = pd.read_excel(source)
            
            if df.empty:
                return []
                
            # v3.5: Î¤Î¿ "Ï€Î±ÎºÎµÏ„Î¬ÏÎ¿Ï…Î¼Îµ" ÎºÎ¹ Î±Ï…Ï„ÏŒ
            return [{"title": f"File Data ({source_type})", "table": df}]
            
        except Exception as e:
            print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {e}")
            if "openpyxl" in str(e):
                print("--- HINT: ÎœÎ®Ï€Ï‰Ï‚ Î»ÎµÎ¯Ï€ÎµÎ¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· 'openpyxl'; Î¤ÏÎ­Î¾Îµ 'pip install openpyxl' ---")
            return []
    
    elif source_type == "pdf":
        print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ PDF (F1 Engine v3.5)...")
        # 1. Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± raw data Î±Ï€ÏŒ Ï„Î¿ PDF (Î¼Îµ Ï„Î¿Î½ v3.5 F1 Engine)
        raw_data_list = load_data_from_pdf(source) 
        
        if not raw_data_list:
            return []
            
        # 2. Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î· Î›Î™Î£Î¤Î‘ Î¼Îµ Ï„Î± "Ï€Î±ÎºÎ­Ï„Î±"
        print(f"--- Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î›Î™Î£Î¤Î‘Î£ Î¼Îµ {len(raw_data_list)} 'Ï€Î±ÎºÎ­Ï„Î±' (Ï€ÏÎ¹Î½ Ï„Î¿Î½ ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®) ---")
        return raw_data_list 

    # ... (rest of the placeholders) ...
    elif source_type == "alphavantage" or source_type == "premium":
        print(f"âš ï¸ Î— Ï€Î·Î³Î® '{source_type}' Î´ÎµÎ½ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹ Ï€Î»Î®ÏÏ‰Ï‚ ÏƒÎµ Î±Ï…Ï„Î® Ï„Î·Î½ Î­ÎºÎ´Î¿ÏƒÎ·.")
        return []

    else:
        print(f"âŒ ÎœÎ· Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î· Ï€Î·Î³Î®: {source_type}")
        return []


def get_yahoo_data(ticker: str, period: str = "5y") -> pd.DataFrame:
    """
    v3.5: Î¤ÏÏÎ± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î•ÎÎ‘ DataFrame, Î­Ï„Î¿Î¹Î¼Î¿ Î³Î¹Î± "ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·".
    """
    try:
        ticker_obj = yf.Ticker(ticker)
        fin = ticker_obj.financials.T if hasattr(ticker_obj, "financials") else pd.DataFrame()
        bs = ticker_obj.balance_sheet.T if hasattr(ticker_obj, "balance_sheet") else pd.DataFrame()
        cf = ticker_obj.cashflow.T if hasattr(ticker_obj, "cashflow") else pd.DataFrame()
        
        df_list = [df for df in [fin, bs, cf] if not df.empty]
        if not df_list:
            print(f"âš ï¸ $ {ticker}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Î± (financials, balance, cashflow).")
            return pd.DataFrame()
            
        # v3.3 Fix: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½ Î±Ï€ÏŒ Ï„Î¿ Yahoo (Ï€.Ï‡. 'Cost Of Revenue')
        clean_df_list = []
        for df in df_list:
            df = df.loc[~df.index.duplicated(keep='first')]
            clean_df_list.append(df)
            
        df = pd.concat(clean_df_list, axis=1)
        df = df.loc[:, ~df.columns.duplicated(keep='first')]
        
        df.reset_index(inplace=True)
        df.rename(columns={'index': 'Date'}, inplace=True)
        df['Year'] = pd.to_datetime(df['Date']).dt.year
        df.columns = [str(c).strip() for c in df.columns]
        
        # v3.5: ÎŸ "ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®Ï‚" ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ Ï€Î»Î­Î¿Î½ ÏƒÏ„Î¿ app.py
        # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ "Î±ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Î¿" Ï€Î¯Î½Î±ÎºÎ± Ï„Î¿Ï… Yahoo
        return df
        
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î· Î»Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Yahoo ($ {ticker}):", e)
        return pd.DataFrame()

# -----------------------------
# ğŸ”¹ Company basic info & peers (Helpers for Terminal)
# -----------------------------
def load_company_info(ticker: str) -> Tuple[pd.DataFrame, str]:
    """
    v3.6: Î¤ÏÏÎ± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎšÎ‘Î™ Ï„Î· Ï‡ÏÏÎ± (Country) Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ info_df
    """
    try:
        company = yf.Ticker(ticker)
        info = company.info or {}
        
        industry = info.get("industry", "General") 
        if not industry or pd.isna(industry): industry = "General"
        
        country = info.get("country", "Unknown") # <-- v3.6: Î— ÎÎ•Î‘ Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—

        df = pd.DataFrame([{
            "ÎŒÎ½Î¿Î¼Î±": info.get("longName", "Î†Î³Î½Ï‰ÏƒÏ„Î¿"),
            "ÎšÎ»Î¬Î´Î¿Ï‚": industry,
            "Î§ÏÏÎ±": country, # <-- v3.6: Î— ÎÎ•Î‘ Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—
            "ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·": info.get("marketCap", None),
            "P/E": info.get("trailingPE", None),
            "ROE": info.get("returnOnEquity", None),
        }])
        
        return df, industry
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î· Î»Î®ÏˆÎ· info ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ ($ {ticker}): {e}")
        return pd.DataFrame(), "General"
# === === === === === === === === === ===

def get_industry_peers(ticker: str):
    print("Î— Î»Î®ÏˆÎ· Peers ÎµÎºÏ„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ terminal.")
    return []
def calculate_industry_averages(peers: list):
    return None
def compare_company_to_industry(company_df, industry_avg):
    print("Î— ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ· ÎºÎ»Î¬Î´Î¿Ï… ÎµÎºÏ„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ terminal.")


# -----------------------------
# ğŸ”¹ ÎšÏÏÎ¹Î¿ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± (Terminal flow)
# -----------------------------
def main():
    print("ğŸ“Š Financial Analysis Tool â€” Terminal (v3.5 - Deprecated)\n")
    print("--- Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Terminal mode. ---")
    print("--- Î“Î¹Î± Ï„Î¿ Ï€Î»Î®ÏÎµÏ‚ GUI, Ï„ÏÎ­Î¾Îµ: streamlit run app.py ---")
    
    choice = "yahoo" 
    raw = input("Î”ÏÏƒÎµ ticker Î® ÏŒÎ½Î¿Î¼Î± ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Ï€.Ï‡. AAPL Î® 'JP Morgan Chase'): ").strip()
    if not raw: return

    ticker = resolve_to_ticker(raw, source_type=choice)
    if ticker is None: return

    info_df, industry = load_company_info(ticker)
    print("\n--- Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î•Ï„Î±Î¹ÏÎµÎ¯Î±Ï‚ ---")
    print(info_df.to_string(index=False))

    # v3.5: Î¤Î¿ get_company_df ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î›Î™Î£Î¤Î‘
    data_list = get_company_df(ticker, source_type=choice, period="max")
    if not data_list: 
        print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
        return

    # v3.5: Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï„Î¿ ÏƒÏ„ÎµÎ¯Î»Î¿Ï…Î¼Îµ ÏƒÏ„Î¿Î½ "ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®" ÎµÎ´Ï
    company_df_raw = data_list[0]["table"]
    company_df = normalize_dataframe(company_df_raw, source_type="yahoo")

    if company_df is None or company_df.empty: 
        print("âš ï¸ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± 'ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚' Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")
        return

    result = calculate_financial_ratios(company_df, sector=industry)
    ratios_df = result.get("ratios")
    
    print("\n--- Î”ÎµÎ¯ÎºÏ„ÎµÏ‚ Î•Ï„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Î£ÏÎ½Ï„Î¿Î¼Î· Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·) ---")
    if isinstance(ratios_df, pd.DataFrame) and not ratios_df.empty:
        with pd.option_context('display.max_columns', None, 'display.width', 200):
            print(ratios_df.head().to_string(index=False))
    else:
        print("âš ï¸ Î”ÎµÎ½ Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚.")
    print("\nâœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏ„Î¿ Terminal.")


if __name__ == "__main__":
    main()