# test_loader.py (v3.7 - Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÏƒÎµ ÏƒÏ„Î±Î¸ÎµÏÎ® Î­ÎºÎ´Î¿ÏƒÎ·)
import os
import sys
import pandas as pd
import yfinance as yf
import requests
from typing import Optional, Tuple, List, Dict, Any
import re 
import io

# === === === === === === === === ===
# === v3.7: ÎŸ ÎÎ•ÎŸÎ£ "TURBO" ÎšÎ™ÎÎ—Î¤Î—Î¡Î‘Î£ ===
import fitz  # PyMuPDF
# === === === === === === === === ===

# (Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Ï„Î¿Î½ Î³Î¿Î½Î¹ÎºÏŒ Ï†Î¬ÎºÎµÎ»Î¿ ÏƒÏ„Î¿ path Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï„Î¿ 'modules')
try:
    base_dir = os.path.dirname(os.path.abspath(__file__))
    if 'modules' not in os.listdir(base_dir):
        base_dir = os.path.dirname(base_dir)
    if 'modules' not in os.listdir(base_dir):
        print("Warning: 'modules' folder not found in parent directory.")
    sys.path.append(base_dir)
    from modules.analyzer import calculate_financial_ratios
except ImportError:
    print("âš ï¸ Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ 'modules/analyzer.py'.")
    def calculate_financial_ratios(*args, **kwargs):
        print("DUMMY ANALYZER: Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¸Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹.")
        return {"ratios": pd.DataFrame(), "categories": {}, "sector": "Unknown"}
except FileNotFoundError:
    print("Warning: Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î²ÏÎµÎ¸ÎµÎ¯ Ï„Î¿ path.")
    try:
        from modules.analyzer import calculate_financial_ratios
    except ImportError:
       def calculate_financial_ratios(*args, **kwargs):
            print("DUMMY ANALYZER: Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¸Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹.")
            return {"ratios": pd.DataFrame(), "categories": {}, "sector": "Unknown"}


# -----------------------------
# ğŸ”¹ Column Normalization Map (Yahoo) - v1.4
# -----------------------------
YAHOO_COLUMN_MAP = {
    'Total Revenue': 'Revenue', 'Revenue': 'Revenue', 'Cost of Revenue': 'CostOfGoodsSold', 
    'Cost Of Revenue': 'CostOfGoodsSold', 'COGS': 'CostOfGoodsSold', 'Gross Profit': 'GrossProfit',
    'Operating Income': 'OperatingIncome', 'Operating Profit': 'OperatingIncome', 'Net Income': 'NetIncome',
    'Total Current Assets': 'CurrentAssets', 'Current Assets': 'CurrentAssets', 'Total Assets': 'TotalAssets',
    'Assets': 'TotalAssets', 'Cash': 'Cash', 'Cash and Cash Equivalents': 'Cash',
    'Cash And Cash Equivalents': 'Cash', 'Inventory': 'Inventory', 'Inventories': 'Inventory',
    'Total Current Liabilities': 'CurrentLiabilities', 'Current Liabilities': 'CurrentLiabilities',
    'Total Liabilities': 'TotalLiabilities', 'Total Liab': 'TotalLiabilities', 'Total Debt': 'TotalDebt', 
    'Total Equity': 'TotalEquity', 'Shareholders Equity': 'TotalEquity', 'StockholdersEquity': 'TotalEquity',
    'Stockholders Equity': 'TotalEquity', 'Stockholder Equity': 'TotalEquity', 
    'Total Stockholder Equity': 'TotalEquity', 'Total Stockholders Equity': 'TotalEquity', 
    'Common Stock Equity': 'TotalEquity',
    'Total Cash From Operating Activities': 'OperatingCashFlow', 'Operating Cash Flow': 'OperatingCashFlow',
    'Shares Outstanding': 'SharesOutstanding', 'Total Loans': 'Loans', 'Total Deposits': 'Deposits', 
    'Net Interest Income': 'NetInterestIncome', 'Average Earning Assets': 'AverageEarningAssets', 
    'Research And Development': 'R&D', 'R&D Expenses': 'R&D', 'Oil Production': 'OilProduction', 
    'Gas Production': 'GasProduction', 'Operating Expenses': 'OperatingExpenses',
}


# -----------------------------
# ğŸ”¹ Column Normalization Map (Generic) - v1.5
# -----------------------------
GENERIC_FILE_MAP = {
    # (Î‘Ï…Ï„ÏŒÏ‚ Î¿ Ï‡Î¬ÏÏ„Î·Ï‚ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ *Î¼ÎµÏ„Î¬* Ï„Î¿ "Pivot")
    'Total Revenue': 'Revenue', 'Revenue': 'Revenue', 'Sales': 'Revenue', 'Turnover': 'Revenue', 'ÎˆÏƒÎ¿Î´Î±': 'Revenue',
    'Cost of Revenue': 'CostOfGoodsSold', 'COGS': 'CostOfGoodsSold', 'Cost of Sales': 'CostOfGoodsSold',
    'Gross Profit': 'GrossProfit', 'Gross Income': 'GrossProfit',
    'Operating Income': 'OperatingIncome', 'Operating Profit': 'OperatingIncome',
    'Net Income': 'NetIncome', 'Profit After Tax': 'NetIncome', 'ÎšÎ±Î¸Î±ÏÎ¬ ÎšÎ­ÏÎ´Î·': 'NetIncome',
    'Total Current Assets': 'CurrentAssets', 'Current Assets': 'CurrentAssets',
    'Total Current Liabilities': 'CurrentLiabilities', 'Current Liabilities': 'CurrentLiabilities',
    'Total Assets': 'TotalAssets', 'Assets': 'TotalAssets', 'Î•Î½ÎµÏÎ³Î·Ï„Î¹ÎºÏŒ': 'TotalAssets',
    'Total Liabilities': 'TotalLiabilities', 'Total Liab': 'TotalLiabilities', 'Total Debt': 'TotalDebt', 'Debt': 'TotalDebt', 'Î¥Ï€Î¿Ï‡ÏÎµÏÏƒÎµÎ¹Ï‚': 'TotalLiabilities',
    'Total Equity': 'TotalEquity', 'Shareholders Equity': 'TotalEquity', 'StockholdersEquity': 'TotalEquity',
    'Total Stockholder Equity': 'TotalEquity', 'Stockholder Equity': 'TotalEquity', 'Total Stockholders Equity': 'TotalEquity', 
    'Common Stock Equity': 'TotalEquity', 'Stockholders Equity': 'TotalEquity', 
    'Cash': 'Cash', 'Cash and Cash Equivalents': 'Cash', 'Cash And Cash Equivalents': 'Cash',
    'Inventory': 'Inventory', 'Inventories': 'Inventory',
    'Shares Outstanding': 'SharesOutstanding', 'Basic Shares Outstanding': 'SharesOutstanding',
    'Total Cash From Operating Activities': 'OperatingCashFlow', 'Operating Cash Flow': 'OperatingCashFlow',
    'Total Loans': 'Loans', 'Loans': 'Loans', 'Total Deposits': 'Deposits', 'Deposits': 'Deposits',
    'Net Interest Income': 'NetInterestIncome', 'Average Earning Assets': 'AverageEarningAssets',
    'Research And Development': 'R&D', 'R&D Expenses': 'R&D',
}

def clean_value_unstructured(val):
    """ 
    v3.7: (ÎœÎµÏ„Î¿Î½Î¿Î¼Î¬ÏƒÏ„Î·ÎºÎµ Î±Î»Î»Î¬ ÎºÎ¬Î½ÎµÎ¹ Ï„Î·Î½ Î¯Î´Î¹Î± Î´Î¿Ï…Î»ÎµÎ¹Î¬)
    ÎšÎ±Î¸Î±ÏÎ¹ÏƒÏ„Î®Ï‚ Î³Î¹Î± Ï„Î¹Î¼Î­Ï‚ Ï€Î¹Î½Î¬ÎºÏ‰Î½.
    """
    if val is None: return pd.NA
    s = str(val).strip()
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î½Î¿Î¼Î¹ÏƒÎ¼Î¬Ï„Ï‰Î½, commmas, ÎºÎ±Î¹ Î³ÏÎ±Î¼Î¼ÏÎ½
    s = s.replace('$', '').replace(',', '').replace('â€”', '0').replace('â‚¬', '').replace('Â£', '')
    
    # Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±ÏÎ½Î·Ï„Î¹ÎºÏÎ½ (Ï€.Ï‡. "(1,234.5)")
    if s.startswith('(') and s.endswith(')'):
        s = '-' + s[1:-1]
        
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Ï…Ï‡ÏŒÎ½ " (1)" Î® "[2]" (references)
    s = re.sub(r'\s*[\(\[]\d+[\)\]]', '', s) 
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Ï…Ï‡ÏŒÎ½ " %"
    s = s.replace('%', '')
    
    # Î‘Î½ Î¼ÎµÎ¯Î½ÎµÎ¹ ÎºÎµÎ½ÏŒ, ÎµÎ¯Î½Î±Î¹ 0 (Î® ÎÎ‘ Î³Î¹Î± Î½Î± Î¼Î·Î½ ÏƒÏ€Î¬ÏƒÎµÎ¹ Ï„Î¿ numeric)
    if s == "":
        return pd.NA
        
    return s

def sanitize_columns(df_to_fix):
    """ÎœÎµÏ„Î¿Î½Î¿Î¼Î¬Î¶ÎµÎ¹ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ (Ï€.Ï‡. 'Amount', 'Amount_2')"""
    if df_to_fix.empty:
        return df_to_fix
        
    new_cols = []
    col_counts = {}
    
    # v3.4 Fix: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ MultiIndex (Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ Î´Î¹Ï€Î»Î¬ headers)
    if df_to_fix.columns.nlevels > 1:
        print("   -> Warning: Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎµ MultiIndex, Î±Ï€Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·...")
        # Î•Î½ÏÎ½ÎµÎ¹ Ï„Î± ÎµÏ€Î¯Ï€ÎµÎ´Î±, Ï€.Ï‡. ('Revenue', '2023') -> 'Revenue_2023'
        df_to_fix.columns = ['_'.join(map(str, col)).strip().replace(r'Unnamed: \d+_level_\d_', '', regex=True) for col in df_to_fix.columns.values]

    for col in df_to_fix.columns:
        if not isinstance(col, str):
            col = str(col) if col is not None else "Unnamed"
        
        # v3.4 Fix: Î‘Ï†Î±Î¯ÏÎµÏƒÎ· "Unnamed" Î±Ï€ÏŒ headers
        col = re.sub(r'Unnamed: \d+', '', col).strip()
        
        if col in col_counts:
            col_counts[col] += 1
            new_col_name = f"{col}_{col_counts[col]}" # Ï€.Ï‡. "Amount_2"
        else:
            col_counts[col] = 1
            new_col_name = col
        
        # v3.4 Fix: Î‘Î½ Î· ÏƒÏ„Î®Î»Î· Î¼ÎµÎ¯Î½ÎµÎ¹ Ï„ÎµÎ»ÎµÎ¯Ï‰Ï‚ ÎºÎµÎ½Î®, Î´ÏÏƒÎµ Ï„Î·Ï‚ Î­Î½Î± ÏŒÎ½Î¿Î¼Î±
        if new_col_name == "":
            new_col_name = f"Unnamed_{col_counts.get('', 0)}"
            col_counts[''] = col_counts.get('', 0) + 1
            
        new_cols.append(new_col_name)
    
    df_to_fix.columns = new_cols
    return df_to_fix


def normalize_dataframe(df: pd.DataFrame, source_type: str) -> pd.DataFrame:
    """
    "ÎŸ ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®Ï‚" (v3.6)
    Î Î±Î¯ÏÎ½ÎµÎ¹ Î­Î½Î±Î½ *Î¼ÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î¿*, ÏƒÏ‡ÎµÎ´ÏŒÎ½-ÎºÎ±Î¸Î±ÏÏŒ Ï€Î¯Î½Î±ÎºÎ± (Ï€.Ï‡. Î™ÏƒÎ¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ)
    ÎºÎ±Î¹ Ï„Î¿Î½ "Î³Ï…ÏÎ½Î¬ÎµÎ¹" (Pivot) ÏÏƒÏ„Îµ Î¿Î¹ Ï‡ÏÎ¿Î½Î¹Î­Ï‚ Î½Î± Î³Î¯Î½Î¿Ï…Î½ ÏƒÏ„Î®Î»ÎµÏ‚.
    """
    if df.empty:
        return df

    if source_type == "yahoo":
        mapping = YAHOO_COLUMN_MAP
    elif source_type in ["csv", "excel", "pdf"]:
        mapping = GENERIC_FILE_MAP
    else:
        print(f"âš ï¸ Warning: Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ source_type '{source_type}'. Î§ÏÎ®ÏƒÎ· 'GENERIC_FILE_MAP'.")
        mapping = GENERIC_FILE_MAP

    normalized_df = pd.DataFrame()
    
    # === PIVOT LOGIC ===
    # v3.7: Î¤Î¿ Pivot Ï„ÏÎ­Ï‡ÎµÎ¹ Ï€Î»Î­Î¿Î½ Î³Î¹Î± PDF, ÎºÎ±Î¹ Î³Î¹Î± CSV/Excel *Ï‡Ï‰ÏÎ¯Ï‚* Ï‡ÏÎ¿Î½Î¹Î­Ï‚
    run_pivot = False
    if source_type == "pdf":
        run_pivot = True
    elif source_type in ["csv", "excel"] and 'Year' not in df.columns and 'Date' not in df.columns:
        run_pivot = True

    if run_pivot:
        print(f"  [Normalize] -> Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎµ {source_type}. Î•ÎºÏ„Î­Î»ÎµÏƒÎ· 'Pivot'...")
        try:
            # 1. Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î±
            label_col = str(df.columns[0]).strip()
            if label_col == "" or label_col.lower() == "nan" or label_col.lower().startswith("unnamed"):
                print(f"  [Normalize] -> Warning: Î— Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· '{label_col}' ÎµÎ¯Î½Î±Î¹ Î¬Ï‡ÏÎ·ÏƒÏ„Î·. Î”Î¿ÎºÎ¹Î¼Î® Ï„Î·Ï‚ 2Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚.")
                label_col = str(df.columns[1]).strip()
                if label_col == "" or label_col.lower() == "nan" or label_col.lower().startswith("unnamed"):
                    print("  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î®Î»Î· Î³Î¹Î± Ï„Î± labels.")
                    return pd.DataFrame()
            
            # 2. Î¤Î· Î¸Î­Ï„Î¿Ï…Î¼Îµ Ï‰Ï‚ Index
            if df[label_col].duplicated().any():
                df[label_col] = df[label_col].astype(str).str.strip()
                df[label_col] = df.groupby(label_col).cumcount().astype(str) + '_' + df[label_col]
                df[label_col] = df[label_col].str.replace('0_', '', n=1)
                
            df = df.set_index(label_col)
            
            # 3. "Î“Ï…ÏÎ½Î¬Î¼Îµ" (Transpose) Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ±
            df = df.T
            
            # 4. Î•Ï€Î±Î½Î±Ï†Î­ÏÎ¿Ï…Î¼Îµ Ï„Î¿ index (Ï€Î¿Ï… Ï„ÏÏÎ± Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Ï‡ÏÎ¿Î½Î¹Î­Ï‚/Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚)
            df = df.reset_index()
            
            # 5. Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î¿ 'Year'
            year_col = str(df.columns[0]) 
            df['Year'] = df[year_col].astype(str).str.extract(r'(?<!\d\s)(\d{4})(?!\d)')
            
            df = df.dropna(subset=['Year']) 
            if df.empty:
                print(f"  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï‡ÏÎ¿Î½Î¹Î­Ï‚ ÏƒÏ„Î¿ header (ÏƒÏ„Î®Î»Î· '{year_col}').")
                return pd.DataFrame()

            print(f"  [Normalize] -> 'Pivot' ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚.")
        except Exception as e:
            print(f"  [Normalize] -> âŒ Î‘Î ÎŸÎ¤Î¥Î§Î™Î‘ 'Pivot': {e}")
            return pd.DataFrame() # Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î±
    
    # v3.7: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î³Î¹Î± Yahoo/CSV/Excel Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î®Î´Î· "Î³Ï…ÏÎ¹ÏƒÎ¼Î­Î½Î±"
    elif source_type == "yahoo":
         df = df 
    elif source_type in ["csv", "excel"]:
        if 'Year' not in df.columns and 'Date' in df.columns:
            df['Year'] = pd.to_datetime(df['Date']).dt.year
        df = df

    # === MAPPING LOGIC ===
    for col in ['Year', 'Date']:
        if col in df.columns and col not in normalized_df.columns:
            normalized_df[col] = df[col]

    df.columns = [str(col).replace('\n', ' ').strip() for col in df.columns]
    df_columns_stripped = {str(col).strip(): col for col in df.columns}
        
    for source_col, standard_col in mapping.items():
        matching_source_col = None
        source_col_clean = str(source_col).strip()
        
        if source_col_clean in df_columns_stripped:
            matching_source_col = df_columns_stripped[source_col_clean]
        else: 
            source_col_lower = source_col_clean.lower()
            for df_col_stripped, df_col_original in df_columns_stripped.items():
                if df_col_stripped.lower() == source_col_lower:
                    matching_source_col = df_col_original
                    break

        if matching_source_col:
            if standard_col not in normalized_df.columns:
                clean_col = pd.to_numeric(df[matching_source_col].astype(str).map(clean_value_unstructured), errors='coerce')
                normalized_df[standard_col] = clean_col

    if 'TotalLiabilities' not in normalized_df.columns and 'TotalDebt' in normalized_df.columns:
        normalized_df['TotalLiabilities'] = normalized_df['TotalDebt']
        print("  [Normalize] Info: 'TotalLiabilities' not found. Using 'TotalDebt' as a proxy.")

    return normalized_df

# -----------------------------
# ğŸ”¹ Utilities: (Search, Premium, Industry Lookups)
# -----------------------------
YAHOO_SEARCH_URL = "https://query2.finance.yahoo.com/v1/finance/search"

def search_company_by_name(name: str, limit: int = 10):
    try:
        params = {"q": name, "quotesCount": limit, "newsCount": 0}
        r = requests.get(YAHOO_SEARCH_URL, params=params, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        data = r.json()
        results = []
        for item in data.get("quotes", []):
            results.append({
                "symbol": item.get("symbol"),
                "name": item.get("shortname") or item.get("longname") or item.get("displayName") or item.get("name"),
                "exchange": item.get("exchange"),
                "type": item.get("typeDisp")
            })
        return results
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ search: {e}")
        return []

def resolve_to_ticker(user_input: str, source_type: str = "yahoo") -> Optional[str]:
    candidate = user_input.strip()
    
    print(f"Info: Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î³Î¹Î± '{candidate}'...")
    matches = search_company_by_name(candidate, limit=10)
    
    is_streamlit = 'streamlit' in sys.modules
    if not matches:
        if is_streamlit:
            print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚.")
            return None
        else:
            print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚.")
            return None
    
    if is_streamlit:
        print(f"Info: Î’ÏÎ­Î¸Î·ÎºÎµ '{matches[0]['symbol']}' Î³Î¹Î± Ï„Î¿ '{candidate}'.")
        return matches[0]['symbol']
    
    print("\nÎ’ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚:")
    for i, m in enumerate(matches, start=1):
        name = m.get("name") or "â€”"; symbol = m.get("symbol") or "â€”"
        exch = m.get("exchange") or ""; typ = m.get("type") or ""
        print(f"{i}. {name} ({symbol}) {exch} {typ}")
    sel = input("Î•Ï€Î­Î»ÎµÎ¾Îµ Î±ÏÎ¹Î¸Î¼ÏŒ Ï„Î·Ï‚ ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Î® Î¬ÏƒÎµ ÎºÎµÎ½ÏŒ Î³Î¹Î± Î±ÎºÏÏÏ‰ÏƒÎ·): ").strip()
    try:
        if sel == "": return None
        sel_i = int(sel) - 1
        if 0 <= sel_i < len(matches):
            return matches[sel_i]["symbol"]
        else:
            print("ÎœÎ· Î­Î³ÎºÏ…ÏÎ· ÎµÏ€Î¹Î»Î¿Î³Î®."); return None
    except Exception:
        print("ÎœÎ· Î­Î³ÎºÏ…ÏÎ· ÎµÎ¯ÏƒÎ¿Î´Î¿Ï‚ (ÎŠÏƒÏ‰Ï‚ Î­Î´Ï‰ÏƒÎµÏ‚ Ticker Î±Î½Ï„Î¯ Î³Î¹Î± Î‘ÏÎ¹Î¸Î¼ÏŒ;)."); return None

def get_premium_data(ticker: str, api_key: Optional[str] = None, source: str = "premium") -> pd.DataFrame:
    # (Placeholder)
    return pd.DataFrame()

# -----------------------------
# ğŸ”¹ PDF Data Extractor (v3.7 - "Turbo Engine" PyMuPDF)
# -----------------------------

# Î‘Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· load_data_from_pdf ÏƒÏ„Î¿ test_loader.py

# test_loader.py - load_data_from_pdf (Safe & Compatible Mode)

def load_data_from_pdf(file_path: str) -> List[Dict[str, Any]]:
    """
    v3.9: Turbo Engine Î¼Îµ "Text Strategy" (Î£Ï…Î¼Î²Î±Ï„Î® ÎˆÎºÎ´Î¿ÏƒÎ·).
    Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î· Î´Î¹Î¬Ï„Î±Î¾Î· Ï„Î¿Ï… ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï€Î¯Î½Î±ÎºÎµÏ‚ Ï‡Ï‰ÏÎ¯Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚.
    """
    print(f"ğŸ“„ ÎˆÎ½Î±ÏÎ¾Î· ÏƒÎ¬ÏÏ‰ÏƒÎ·Ï‚ PDF (v3.9 - Text Strategy): {file_path}")
    
    all_data_packages = []
    
    try:
        doc = fitz.open(file_path)
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± PyMuPDF: {e}")
        return []

    # Î£Î¬ÏÏ‰ÏƒÎ· Ï€ÏÏÏ„Ï‰Î½ 20 ÏƒÎµÎ»Î¯Î´Ï‰Î½
    pages_to_scan = doc[:20] if len(doc) > 20 else doc

    for page_num, page in enumerate(pages_to_scan):
        try:
            # === Î— Î‘Î›Î›Î‘Î“Î— Î•Î™ÎÎ‘Î™ Î•Î”Î© ===
            # Î‘Ï†Î±Î¹ÏÎ­ÏƒÎ±Î¼Îµ Ï„Î± 'tolerance' Ï€Î¿Ï… Ï‡Ï„Ï…Ï€Î¿ÏÏƒÎ±Î½ Î»Î¬Î¸Î¿Ï‚.
            # ÎšÏÎ±Ï„Î®ÏƒÎ±Î¼Îµ Ï„Î± strategies Ï€Î¿Ï… Î²ÏÎ¯ÏƒÎºÎ¿Ï…Î½ Ï„Î¿Ï…Ï‚ Ï€Î¯Î½Î±ÎºÎµÏ‚ Ï„Î·Ï‚ Microsoft.
            table_finder = page.find_tables(
                vertical_strategy="text", 
                horizontal_strategy="text"
            )
            
            tables = table_finder.tables
            
            if not tables:
                continue

            print(f"   > Î£ÎµÎ»Î¯Î´Î± {page_num+1}: Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(tables)} Ï€Î¹Î¸Î±Î½Î¿Î¯ Ï€Î¯Î½Î±ÎºÎµÏ‚...")

            for i, table in enumerate(tables):
                try:
                    df = table.to_pandas()
                    
                    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚
                    df = df.dropna(how='all').fillna("")
                    
                    # Î¦Î¯Î»Ï„ÏÎ¿ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚
                    if df.shape[0] < 3 or df.shape[1] < 2:
                        continue

                    # Header Detection (ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ Î­Ï„Î¿Ï‚)
                    header_idx = -1
                    for r_idx, row in df.iterrows():
                        row_str = " ".join(row.astype(str))
                        if re.search(r'20[1-3][0-9]', row_str):
                            header_idx = r_idx
                            break
                    
                    if header_idx != -1:
                        new_header = df.iloc[header_idx]
                        df_data = df.iloc[header_idx+1:]
                        df_data.columns = new_header
                    else:
                        df_data = df 

                    # Sanitize
                    df_sanitized = sanitize_columns(df_data)
                    df_clean = df_sanitized.apply(lambda col: col.map(clean_value_unstructured))

                    # Î Î±ÎºÎµÏ„Î¬ÏÎ¹ÏƒÎ¼Î±
                    all_data_packages.append({
                        "title": f"Page_{page_num+1}_Table_{i+1}",
                        "table": df_clean
                    })
                    
                except Exception as e:
                    continue 
        
        except Exception as e:
            print(f"   -> Error page {page_num+1}: {e}")
            continue

    if not all_data_packages:
        print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€Î¯Î½Î±ÎºÎµÏ‚.")
        return []

    print(f"   Î•Ï€Î¹Ï„Ï…Ï‡Î¯Î±! Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(all_data_packages)} 'Ï€Î±ÎºÎ­Ï„Î±'.")
    return all_data_packages

# -----------------------------
# ğŸ”¹ Loader Î³Î¹Î± Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï€Î·Î³Î­Ï‚
# -----------------------------
def get_company_df(source: str, source_type: str = "yahoo", api_key: Optional[str] = None, period: str = "5y") -> List[Dict[str, Any]]:
    """
    v3.7: Î•Î Î™Î£Î¤Î¡Î•Î¦Î•Î™ Î Î‘ÎÎ¤Î‘ Î›Î™Î£Î¤Î‘ ÎœÎ• "Î Î‘ÎšÎ•Î¤Î‘" [ {"title": ..., "table": ...} ]
    """
    source_type = source_type.lower()

    if source_type == "yahoo":
        print("âš¡ Î›Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Yahoo Finance...")
        yahoo_df = get_yahoo_data(source, period=period)
        if yahoo_df.empty:
            return []
        return [{"title": "Yahoo Finance Data", "table": yahoo_df}]
        
    elif source_type in ["csv", "excel"]:
        print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ {source_type.upper()}: {source}")
        try:
            if source_type == "csv":
                df = pd.read_csv(source)
            else:
                df = pd.read_excel(source)
            
            if df.empty:
                return []
            return [{"title": f"File Data ({source_type})", "table": df}]
            
        except Exception as e:
            print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {e}")
            if "openpyxl" in str(e):
                print("--- HINT: ÎœÎ®Ï€Ï‰Ï‚ Î»ÎµÎ¯Ï€ÎµÎ¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· 'openpyxl'; Î¤ÏÎ­Î¾Îµ 'pip install openpyxl' ---")
            return []
    
    elif source_type == "pdf":
        print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ PDF (F1 Engine v3.7 - Turbo)...")
        # 1. Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± raw data Î±Ï€ÏŒ Ï„Î¿ PDF (Î¼Îµ Ï„Î¿Î½ v3.7 Turbo Engine)
        raw_data_list = load_data_from_pdf(source) 
        
        if not raw_data_list:
            return []
            
        # 2. Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î· Î›Î™Î£Î¤Î‘ Î¼Îµ Ï„Î± "Ï€Î±ÎºÎ­Ï„Î±"
        print(f"--- Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î›Î™Î£Î¤Î‘Î£ Î¼Îµ {len(raw_data_list)} 'Ï€Î±ÎºÎ­Ï„Î±' (Ï€ÏÎ¹Î½ Ï„Î¿Î½ ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®) ---")
        return raw_data_list 

    # ... (rest of the placeholders) ...
    elif source_type == "alphavantage" or source_type == "premium":
        print(f"âš ï¸ Î— Ï€Î·Î³Î® '{source_type}' Î´ÎµÎ½ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹ Ï€Î»Î®ÏÏ‰Ï‚ ÏƒÎµ Î±Ï…Ï„Î® Ï„Î·Î½ Î­ÎºÎ´Î¿ÏƒÎ·.")
        return []

    else:
        print(f"âŒ ÎœÎ· Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î· Ï€Î·Î³Î®: {source_type}")
        return []


def get_yahoo_data(ticker: str, period: str = "5y") -> pd.DataFrame:
    """
    v3.7: Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î•ÎÎ‘ DataFrame, Î­Ï„Î¿Î¹Î¼Î¿ Î³Î¹Î± "ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·" (Î±Î»Î»Î¬ "Î±ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Î¿").
    """
    try:
        ticker_obj = yf.Ticker(ticker)
        fin = ticker_obj.financials.T if hasattr(ticker_obj, "financials") else pd.DataFrame()
        bs = ticker_obj.balance_sheet.T if hasattr(ticker_obj, "balance_sheet") else pd.DataFrame()
        cf = ticker_obj.cashflow.T if hasattr(ticker_obj, "cashflow") else pd.DataFrame()
        
        df_list = [df for df in [fin, bs, cf] if not df.empty]
        if not df_list:
            print(f"âš ï¸ $ {ticker}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Î± (financials, balance, cashflow).")
            return pd.DataFrame()
            
        clean_df_list = []
        for df in df_list:
            df = df.loc[~df.index.duplicated(keep='first')]
            clean_df_list.append(df)
            
        df = pd.concat(clean_df_list, axis=1)
        df = df.loc[:, ~df.columns.duplicated(keep='first')]
        
        df.reset_index(inplace=True)
        df.rename(columns={'index': 'Date'}, inplace=True)
        df['Year'] = pd.to_datetime(df['Date']).dt.year
        df.columns = [str(c).strip() for c in df.columns]
        
        # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ "Î±ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Î¿" Ï€Î¯Î½Î±ÎºÎ± Ï„Î¿Ï… Yahoo
        return df
        
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î· Î»Î®ÏˆÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Yahoo ($ {ticker}):", e)
        return pd.DataFrame()

# -----------------------------
# ğŸ”¹ Company basic info & peers (Helpers for Terminal)
# -----------------------------
def load_company_info(ticker: str) -> Tuple[pd.DataFrame, str]:
    """
    v3.6: Î¤ÏÏÎ± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎšÎ‘Î™ Ï„Î· Ï‡ÏÏÎ± (Country) Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ info_df
    """
    try:
        company = yf.Ticker(ticker)
        info = company.info or {}
        
        industry = info.get("industry", "General") 
        if not industry or pd.isna(industry): industry = "General"
        
        country = info.get("country", "Unknown") # <-- v3.6: Î— ÎÎ•Î‘ Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—

        df = pd.DataFrame([{
            "ÎŒÎ½Î¿Î¼Î±": info.get("longName", "Î†Î³Î½Ï‰ÏƒÏ„Î¿"),
            "ÎšÎ»Î¬Î´Î¿Ï‚": industry,
            "Î§ÏÏÎ±": country, # <-- v3.g: Î— ÎÎ•Î‘ Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—
            "ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·": info.get("marketCap", None),
            "P/E": info.get("trailingPE", None),
            "ROE": info.get("returnOnEquity", None),
        }])
        
        return df, industry
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î· Î»Î®ÏˆÎ· info ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ ($ {ticker}): {e}")
        return pd.DataFrame(), "General"
# === === === === === === === === === ===

def get_industry_peers(ticker: str):
    print("Î— Î»Î®ÏˆÎ· Peers ÎµÎºÏ„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ terminal.")
    return []
def calculate_industry_averages(peers: list):
    return None
def compare_company_to_industry(company_df, industry_avg):
    print("Î— ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ· ÎºÎ»Î¬Î´Î¿Ï… ÎµÎºÏ„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ terminal.")


# -----------------------------
# ğŸ”¹ ÎšÏÏÎ¹Î¿ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± (Terminal flow)
# -----------------------------
def main():
    print("ğŸ“Š Financial Analysis Tool â€” Terminal (v3.5 - Deprecated)\n")
    print("--- Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Terminal mode. ---")
    print("--- Î“Î¹Î± Ï„Î¿ Ï€Î»Î®ÏÎµÏ‚ GUI, Ï„ÏÎ­Î¾Îµ: streamlit run app.py ---")
    
    choice = "yahoo" 
    raw = input("Î”ÏÏƒÎµ ticker Î® ÏŒÎ½Î¿Î¼Î± ÎµÏ„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Ï€.Ï‡. AAPL Î® 'JP Morgan Chase'): ").strip()
    if not raw: return

    ticker = resolve_to_ticker(raw, source_type=choice)
    if ticker is None: return

    info_df, industry = load_company_info(ticker)
    print("\n--- Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î•Ï„Î±Î¹ÏÎµÎ¯Î±Ï‚ ---")
    print(info_df.to_string(index=False))

    # v3.5: Î¤Î¿ get_company_df ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î›Î™Î£Î¤Î‘
    data_list = get_company_df(ticker, source_type=choice, period="max")
    if not data_list: 
        print("âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
        return

    # v3.5: Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï„Î¿ ÏƒÏ„ÎµÎ¯Î»Î¿Ï…Î¼Îµ ÏƒÏ„Î¿Î½ "ÎœÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„Î®" ÎµÎ´Ï
    company_df_raw = data_list[0]["table"]
    company_df = normalize_dataframe(company_df_raw, source_type="yahoo")

    if company_df is None or company_df.empty: 
        print("âš ï¸ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± 'ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚' Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")
        return

    result = calculate_financial_ratios(company_df, sector=industry)
    ratios_df = result.get("ratios")
    
    print("\n--- Î”ÎµÎ¯ÎºÏ„ÎµÏ‚ Î•Ï„Î±Î¹ÏÎµÎ¯Î±Ï‚ (Î£ÏÎ½Ï„Î¿Î¼Î· Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·) ---")
    if isinstance(ratios_df, pd.DataFrame) and not ratios_df.empty:
        with pd.option_context('display.max_columns', None, 'display.width', 200):
            print(ratios_df.head().to_string(index=False))
    else:
        print("âš ï¸ Î”ÎµÎ½ Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚.")
    print("\nâœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏ„Î¿ Terminal.")


if __name__ == "__main__":
    main()